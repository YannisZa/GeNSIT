{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "c76b8620",
      "metadata": {},
      "outputs": [],
      "source": [
        "import os\n",
        "import json\n",
        "import gzip\n",
        "import glob\n",
        "import itertools\n",
        "import scipy.stats\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "from tqdm import tqdm\n",
        "from copy import deepcopy\n",
        "from argparse import Namespace\n",
        "from collections import OrderedDict\n",
        "from itertools import product\n",
        "from functools import partial\n",
        "from multiprocessing import Pool\n",
        "from statsmodels.graphics.tsaplots import plot_acf\n",
        "from multiresticodm.utils import *\n",
        "from multiresticodm.sim_models.production_constrained import *\n",
        "from multiresticodm.outputs import Outputs"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "b718b815",
      "metadata": {},
      "outputs": [],
      "source": [
        "%matplotlib inline\n",
        "\n",
        "# AUTO RELOAD EXTERNAL MODULES\n",
        "%load_ext autoreload\n",
        "%autoreload 2"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "880cdfcb",
      "metadata": {},
      "source": [
        "# Import samples"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "9b1c638c",
      "metadata": {},
      "outputs": [],
      "source": [
        "settings = {'table_total':33704}\n",
        "\n",
        "foldername = 'exp14_JointTableSIMLatentMCMC_HighNoise_both_margins_permuted_cells_10%_20_03_2023_10_29_54'\n",
        "\n",
        "outputs = Outputs(\n",
        "    os.path.join('../data/outputs/cambridge_work_commuter_lsoas_to_msoas/',foldername),\n",
        "    settings,\n",
        "    sample_names=['intensity','theta','log_destination_attraction','table']\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "4302b04e",
      "metadata": {},
      "outputs": [],
      "source": [
        "# #  for sample_name in self.experiment.results.keys():\n",
        "# sample_name = 'intensity'\n",
        "# dims = np.shape(outputs.experiment.results['table'])[1:]\n",
        "# print(sample_name,dims)\n",
        "# cells = sorted([tuple(cell) for cell in product(*[range(dim) for dim in dims])])\n",
        "# for cell in cells:\n",
        "#     data = outputs.experiment.results[sample_name][(...,*cell)]\n",
        "#     plt.figure(figsize=(10,10))\n",
        "#     _ = plt.hist(data)\n",
        "#     plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "082b3361",
      "metadata": {},
      "outputs": [],
      "source": [
        "# Read important metadata (true latent values)\n",
        "I,J = sim.I,sim.dims[1]\n",
        "log_destination_attraction_data = sim.log_destination_attraction\n",
        "true_log_destination_attraction = sim.log_true_destination_attraction\n",
        "\n",
        "# Decide on burnin\n",
        "burnin = 5000\n",
        "table_steps = 1#metadata['mcmc']['contingency_table']['table_steps']\n",
        "colsum_steps = 1#metadata['mcmc']['contingency_table']['column_sum_steps']\n",
        "\n",
        "# Define figure format\n",
        "figure_format = 'eps' #'eps','png'"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "e5d101ac",
      "metadata": {},
      "source": [
        "# Preprocessing"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "9a38ac0e",
      "metadata": {},
      "outputs": [],
      "source": [
        "if sim.ground_truth_known:\n",
        "    theta_true = [sim.alpha_true,sim.beta_true*sim.bmax]\n",
        "    true_log_flows = sim.log_intensity(sim.log_true_destination_attraction,theta_true)\n",
        "    true_flows = np.exp(true_log_flows)\n",
        "    print('Intensities based on ground truth for x')\n",
        "    print(pd.DataFrame(true_flows))\n",
        "\n",
        "# Compute mean intensities\n",
        "lambda_sample_mean = np.exp(np.mean(log_lambda_samples,axis=0))\n",
        "    \n",
        "theta_mean_scaled = np.mean(theta_samples[burnin:,:],axis=0)\n",
        "theta_mean_scaled[1] *= sim.bmax\n",
        "expected_log_flows = sim.log_intensity(np.mean(log_destination_attraction_samples[burnin:,:],axis=0),theta_mean_scaled)\n",
        "expected_flows = np.exp(expected_log_flows)\n",
        "print('Intensities based on mean x, theta')\n",
        "print(pd.DataFrame(expected_flows))"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "e1d39335",
      "metadata": {},
      "source": [
        "# X, Theta Sampling\n",
        "## Trace plots"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "efec9ace",
      "metadata": {},
      "outputs": [],
      "source": [
        "print(f\"{np.mean(theta_samples[burnin:],axis=0)} +/- {np.std(theta_samples[burnin:],axis=0)}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "f87b7a9c",
      "metadata": {},
      "outputs": [],
      "source": [
        "fig,axs = plt.subplots(1,2,figsize=(20,10))\n",
        "\n",
        "axs[0].plot(theta_samples[burnin:, 0],label='samples')\n",
        "axs[0].set_ylabel(r'$\\alpha$',fontsize=18,rotation=0,labelpad=7)\n",
        "axs[0].set_xlabel('MCMC samples',fontsize=18,labelpad=7)\n",
        "if hasattr(sim,'alpha_true'):\n",
        "    axs[0].axhline(y=sim.alpha_true, color='black', linestyle='-',label='true')\n",
        "axs[0].axhline(y=np.mean(theta_samples[burnin:, 0]),color='lime',label=r'$\\mu$')\n",
        "axs[0].set_ylim(0,2.0)\n",
        "axs[0].legend()\n",
        "\n",
        "axs[1].plot(theta_samples[burnin:, 1])\n",
        "axs[1].set_ylabel(r'$\\beta$',fontsize=18,rotation=0,labelpad=7)\n",
        "axs[1].set_xlabel('MCMC samples',fontsize=18,labelpad=7)\n",
        "if hasattr(sim,'beta_true'):\n",
        "    axs[1].axhline(y=sim.beta_true, color='black', linestyle='-',label='true')\n",
        "axs[1].axhline(y=np.mean(theta_samples[burnin:, 1]),color='lime',label=r'$\\mu$')\n",
        "axs[1].set_ylim(0,2.0)\n",
        "axs[1].legend()\n",
        "\n",
        "fig.suptitle(fr'{experiment_type}',fontsize=20)\n",
        "plt.savefig(os.path.join(dirpath,f'figures/parameter_mixing.{figure_format}'),format=figure_format)\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "020ec97b",
      "metadata": {},
      "outputs": [],
      "source": [
        "print(f\"{np.mean(log_destination_attraction_samples[burnin:],axis=0)} +/- {np.std(log_destination_attraction_samples[burnin:],axis=0)}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "b9c8a817",
      "metadata": {},
      "outputs": [],
      "source": [
        "print(sim.log_destination_attraction)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "5eca386f",
      "metadata": {},
      "outputs": [],
      "source": [
        "np.mean(log_destination_attraction_samples[burnin:],axis=0)-sim.log_destination_attraction"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "358ff651",
      "metadata": {},
      "outputs": [],
      "source": [
        "np.mean(log_destination_attraction_samples[burnin:],axis=0)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "81be09b4",
      "metadata": {},
      "outputs": [],
      "source": [
        "log_destination_attraction_data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "8e953d83",
      "metadata": {},
      "outputs": [],
      "source": [
        "1/(sim.gamma/2)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "35ed81b8",
      "metadata": {},
      "outputs": [],
      "source": [
        "sim.noise_var"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "7bc4a070",
      "metadata": {},
      "outputs": [],
      "source": [
        "fig,axs = plt.subplots(1,J,figsize=(20,10))\n",
        "relative_noise = np.sqrt(sim.noise_var)/np.log(sim.dims[1])\n",
        "relative_noise_percentage = round(100*relative_noise)\n",
        "upper_bound = log_destination_attraction_data + np.log((1.0+relative_noise_percentage/100))\n",
        "lower_bound = log_destination_attraction_data - np.log((1.0+relative_noise_percentage/100))\n",
        "for j in range(J):\n",
        "    axs[j].plot(log_destination_attraction_samples[burnin:, j])\n",
        "    axs[j].set_ylabel(fr'$x_{j}$',fontsize=18,rotation=0,labelpad=7)\n",
        "    axs[j].set_xlabel('MCMC samples',fontsize=18,labelpad=7)\n",
        "    axs[j].axhline(y=np.mean(log_destination_attraction_samples[burnin:],axis=0)[j], color='lime', linestyle='-',label='$\\mu$')\n",
        "    axs[j].axhline(y=log_destination_attraction_data[j], color='r', linestyle='-',label='data')\n",
        "    axs[j].axhline(y=sim.log_true_destination_attraction[j], color='black', linestyle='-',label='generated')\n",
        "    axs[j].axhline(y=upper_bound[j], color='r', linestyle='--',label=f'data + {relative_noise_percentage}%')\n",
        "    axs[j].axhline(y=lower_bound[j], color='r', linestyle='--',label=f'data - {relative_noise_percentage}%')\n",
        "    axs[j].legend()\n",
        "fig.suptitle(fr'{experiment_type}',fontsize=20)\n",
        "plt.savefig(os.path.join(dirpath,f'figures/log_destination_attraction_mixing.{figure_format}'),format=figure_format)\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "adf6d16e",
      "metadata": {},
      "outputs": [],
      "source": [
        "plt.figure(figsize=(7,5))\n",
        "plt.scatter(sim.log_destination_attraction-np.mean(log_destination_attraction_samples[burnin:],axis=0),np.mean(log_destination_attraction_samples[burnin:],axis=0))\n",
        "plt.xlabel(r'$\\log(Y_j)-E[\\log(W_j)|Y_j]$',fontsize=16)#,rotation=0,labelpad=90)\n",
        "plt.ylabel(r'$E[\\log(W_j)|Y_j]$',fontsize=16)\n",
        "plt.tight_layout()\n",
        "plt.savefig(os.path.join(dirpath,f'figures/log_destination_attraction_residuals.{figure_format}'),format=figure_format)\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "ce945f7a",
      "metadata": {},
      "outputs": [],
      "source": [
        "plt.figure(figsize=(7,5))\n",
        "plt.scatter(sim.log_destination_attraction,np.mean(log_destination_attraction_samples[burnin:],axis=0))\n",
        "plt.xlabel(r'$\\log(Y_j)$',fontsize=16)#,rotation=0,labelpad=40)\n",
        "plt.ylabel(r'$E[\\log(W_j)|Y_j]$',fontsize=16)\n",
        "plt.tight_layout()\n",
        "plt.savefig(os.path.join(dirpath,f'figures/log_destination_attraction_predictions.{figure_format}'),format=figure_format)\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "c5301143",
      "metadata": {},
      "source": [
        "## 2D theta sampled space"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "1c085cc0",
      "metadata": {},
      "outputs": [],
      "source": [
        "fig = plt.figure(figsize=(10,10))\n",
        "\n",
        "plt.plot(theta_samples[burnin:, 0],theta_samples[burnin:, 1])#,label='samples',marker='x')\n",
        "plt.ylabel(r'$\\beta$',fontsize=18,rotation=0,labelpad=7)\n",
        "plt.xlabel(r'$\\alpha$',fontsize=18,labelpad=7)\n",
        "plt.xlim(0,2)\n",
        "plt.ylim(0,2)\n",
        "if hasattr(sim,'alpha_true') and hasattr(sim,'beta_true'):\n",
        "    plt.plot(sim.alpha_true,sim.beta_true,marker='o',color='r',label='ground truth')\n",
        "plt.plot(np.mean(theta_samples[burnin:,0]),np.mean(theta_samples[burnin:,1]),marker='o',color='y',label='mean')\n",
        "plt.legend()\n",
        "plt.savefig(os.path.join(dirpath,f'figures/parameter_2d_exploration.{figure_format}'),format=figure_format)\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "864896aa",
      "metadata": {},
      "source": [
        "## Histograms"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "96221222",
      "metadata": {},
      "outputs": [],
      "source": [
        "fig,axs = plt.subplots(1,2,figsize=(20,10))\n",
        "\n",
        "axs[0].hist(theta_samples[burnin:, 0],bins=100)\n",
        "axs[0].set_ylabel(r'$\\alpha$',fontsize=18,rotation=0,labelpad=7)\n",
        "axs[0].set_xlabel('MCMC samples',fontsize=18,labelpad=7)\n",
        "if hasattr(sim,'alpha_true'):\n",
        "    axs[0].axvline(x=sim.alpha_true, color='r', linestyle='-',label='generated')\n",
        "axs[0].axvline(x=np.mean(theta_samples[burnin:, 0]), color='lime', linestyle='-',label=f'posterior $\\mu$')\n",
        "axs[0].set_xlim(0,2.0)\n",
        "axs[0].legend()\n",
        "\n",
        "axs[1].hist(theta_samples[burnin:, 1],bins=100)\n",
        "axs[1].set_ylabel(r'$\\beta$',fontsize=18,rotation=0,labelpad=7)\n",
        "axs[1].set_xlabel('MCMC samples',fontsize=18,labelpad=7)\n",
        "if hasattr(sim,'beta_true'):\n",
        "    axs[1].axvline(x=sim.beta_true, color='r', linestyle='-',label='generated')\n",
        "axs[1].axvline(x=np.mean(theta_samples[burnin:, 1]), color='lime', linestyle='-',label=f'posterior $\\mu$')\n",
        "axs[1].set_xlim(0,2.0)\n",
        "axs[1].legend()\n",
        "\n",
        "\n",
        "fig.suptitle(fr'{experiment_type}',fontsize=20)\n",
        "plt.savefig(os.path.join(dirpath,f'figures/parameter_histogram.{figure_format}'),format=figure_format)\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "224782de",
      "metadata": {},
      "source": [
        "## Autocorrelation Plots"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "a2425807",
      "metadata": {},
      "outputs": [],
      "source": [
        "fig,axs = plt.subplots(1,2,figsize=(10,5))\n",
        "\n",
        "plot_acf(theta_samples[burnin:, 0],lags=200,ax=axs[0])\n",
        "axs[0].set_ylim(0,1.1)\n",
        "axs[0].set_ylabel(r'$\\alpha$',rotation=0,labelpad=10,fontsize=14)\n",
        "axs[0].axhline(y=0.2,color='red')\n",
        "axs[0].set_xlabel('Lags')\n",
        "\n",
        "plot_acf(theta_samples[burnin:, 1],lags=200,ax=axs[1])\n",
        "axs[1].set_ylim(0,1.1)\n",
        "axs[1].axhline(y=0.2,color='red')\n",
        "axs[1].set_ylabel(r'$\\beta$',rotation=0,labelpad=10,fontsize=14)\n",
        "axs[1].set_xlabel('Lags')\n",
        "\n",
        "plt.savefig(os.path.join(dirpath,f'figures/parameter_acf.{figure_format}'),format=figure_format)\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "e40c4d96",
      "metadata": {},
      "source": [
        "# Table sample inspection"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "7fc1ced2",
      "metadata": {},
      "outputs": [],
      "source": [
        "ct.table"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "b9c0512c",
      "metadata": {},
      "outputs": [],
      "source": [
        "# Count number of times true table was reconstructed\n",
        "# and build a histogram over table\n",
        "table_histogram = dict([(table_to_str(k), 0) for k in table_samples[burnin::table_steps]])\n",
        "for f in tqdm(table_samples[burnin::table_steps]):\n",
        "    # Append table count to histogram\n",
        "    table_histogram[table_to_str(f)] += 1\n",
        "\n",
        "    \n",
        "# Sort histogram by frequency\n",
        "# table_histogram = {k: v for k, v in sorted(table_histogram.items(), key=lambda item: item[0])}\n",
        "table_histogram = {k: v for k, v in sorted(table_histogram.items(), key=lambda item: -item[1])}\n",
        "n_table_samples = sum(table_histogram.values(), 0.0)\n",
        "table_probabilities = {k: v / n_table_samples for k, v in table_histogram.items()}\n",
        "\n",
        "print(f\"{int(100*table_histogram[table_to_str(ct.table)]/len(table_samples[burnin::table_steps]))}% of table samples matched true table\")\n",
        "print('Matches',table_histogram[table_to_str(ct.table)])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "130dd331",
      "metadata": {},
      "outputs": [],
      "source": [
        "# Check whether true table is identified and in which order\n",
        "# Check how many tables have the right column sums\n",
        "true_table_index = -1\n",
        "true_colsums_indices = []\n",
        "true_colsums_table_strings = []\n",
        "for i,keyvalue in enumerate(table_histogram.items()):\n",
        "    # Monitor correct table samples\n",
        "    if keyvalue[0] == table_to_str(ct.table):\n",
        "        true_table_index = i\n",
        "#         print(f'True table is the {i}th most commonly sampled out of {len(table_histogram)} distinct tables')\n",
        "    # Monitor table samples with corrent column sums\n",
        "    if np.all(abs(str_to_table(keyvalue[0],dims=(I,J)).sum(axis=0) - ct.table.sum(axis=0)) <= 1e-9):\n",
        "        true_colsums_indices.append(i)\n",
        "        true_colsums_table_strings.append(keyvalue[0])\n",
        "print(f'True table is the {true_table_index+1} most commonly sampled out of {len(table_histogram)} distinct tables')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "5195c39b",
      "metadata": {},
      "outputs": [],
      "source": [
        "if sim.ground_truth_known:\n",
        "    # Get multinomial probabilities\n",
        "    _,log_probs,_ = ct_mcmc.log_intensities_to_multinomial_log_probabilities(true_log_flows)\n",
        "    probs = np.exp(log_probs)\n",
        "\n",
        "    # Find mode through search\n",
        "    support = [x for x in itertools.product(range(0,ct.margins[range(self.ndims())]), repeat=J) if sum(x) == ct.margins[range(self.ndims())]]\n",
        "    mode = np.zeros(J)\n",
        "    multiple_modes = []\n",
        "    max_prob = 0\n",
        "    normalisation = 0\n",
        "    total_prob = 0\n",
        "    for v in support:\n",
        "        # Renormalise by limiting the support to vectors that do not contain zeros\n",
        "        if 0 in v:\n",
        "            normalisation += scipy.stats.multinomial.pmf(v,n=ct.margins[range(self.ndims())],p=probs)\n",
        "        total_prob += scipy.stats.multinomial.pmf(v,n=ct.margins[range(self.ndims())],p=probs)\n",
        "    assert abs(total_prob-1.0) <= 1e-7\n",
        "    # Find mode\n",
        "    for v in support:\n",
        "        if scipy.stats.multinomial.pmf(v,n=ct.margins[range(self.ndims())],p=probs)/(1-normalisation) > max_prob:\n",
        "            max_prob = scipy.stats.multinomial.pmf(v,n=ct.margins[range(self.ndims())],p=probs)/(1-normalisation)\n",
        "            mode = v\n",
        "    # Find nearby modes\n",
        "    for v in support:\n",
        "        if abs(scipy.stats.multinomial.pmf(v,n=ct.margins[range(self.ndims())],p=probs)/(1-normalisation)-max_prob)<=1e-4:\n",
        "            multiple_modes.append(v)\n",
        "mode"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "4796a4f2",
      "metadata": {},
      "outputs": [],
      "source": [
        "ct.true_colsums"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "17457077",
      "metadata": {},
      "outputs": [],
      "source": [
        "ct.table"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "2750f96f",
      "metadata": {},
      "outputs": [],
      "source": [
        "# Find table with higher log target under true intensities\n",
        "max_index = -1\n",
        "max_target = -np.infty\n",
        "for i in range(true_table_index+1):\n",
        "    lt = log_product_multinomial_pmf(str_to_table(list(table_histogram.keys())[i],dims=(I,J)),true_log_flows)\n",
        "    if lt > max_target:\n",
        "        max_target = lt\n",
        "        max_index = i\n",
        "print(lt)\n",
        "print(str_to_table(list(table_histogram.keys())[max_index],dims=(I,J)))\n",
        "print(ct.table)\n",
        "print(str_to_table(list(table_histogram.keys())[max_index],dims=(I,J)).sum(axis=0))\n",
        "print(ct.colsums)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "77dc7f5e",
      "metadata": {},
      "outputs": [],
      "source": [
        "plt.figure(figsize=(20,10))\n",
        "plt.bar(range(len(table_histogram)), list(table_histogram.values()), align='center', label='samples')\n",
        "plt.bar(true_colsums_indices, np.array(list(table_histogram.values()))[true_colsums_indices], align='center',color='green',label='true colsums')\n",
        "plt.bar(true_table_index, list(table_histogram.values())[true_table_index], align='center',color='red',label='true table')\n",
        "# _ = plt.xticks(range(len(table_histogram)), list(table_histogram.keys()),rotation=90,fontsize=5)\n",
        "_ = plt.xlim(-1,300)#len()\n",
        "_ = plt.ylabel('Frequency',fontsize=20)\n",
        "_ = plt.xlabel('Table string',fontsize=20)\n",
        "_ = plt.legend(fontsize=20)\n",
        "_ = plt.title(f'{len(table_histogram)} different tables sampled')\n",
        "plt.savefig(os.path.join(dirpath,f'figures/table_histogram.{figure_format}'),format=figure_format)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "bda61e5a",
      "metadata": {},
      "outputs": [],
      "source": [
        "# Slice table histogram to obtain histogram of tables with true column sums\n",
        "true_table_histogram = OrderedDict((k, table_histogram[k]) for k in true_colsums_table_strings)\n",
        "# Sort histogram lexicographically\n",
        "# true_table_histogram = {k: v for k, v in sorted(true_table_histogram.items(), key=lambda item: item[0])}\n",
        "true_table_histogram = {k: v for k, v in sorted(true_table_histogram.items(), key=lambda item: -item[1])}\n",
        "# Store updated index of true table\n",
        "true_table_new_index = list(true_table_histogram.keys()).index(table_to_str(ct.table))\n",
        "\n",
        "print(f\"{int(100*np.sum(list(true_table_histogram.values()))/len(table_samples[burnin::table_steps]))}% of table samples matched true column sums\")\n",
        "print('Matches',np.sum(list(true_table_histogram.values())))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "e7b8bd3c",
      "metadata": {},
      "outputs": [],
      "source": [
        "plt.figure(figsize=(20,10))\n",
        "plt.bar(range(len(true_table_histogram)), np.fromiter(true_table_histogram.values(),dtype=int), align='center',color='green',label='true colsums')\n",
        "plt.bar(true_table_new_index, true_table_histogram[table_to_str(ct.table)], align='center',color='red',label='true table')\n",
        "_ = plt.xticks(range(-1,len(true_table_histogram)-1), list(true_table_histogram.keys()),rotation=45)\n",
        "_ = plt.xlim(-1,len(true_table_histogram))\n",
        "_ = plt.ylabel('Frequency',fontsize=20)\n",
        "_ = plt.xlabel('Table string',fontsize=20)\n",
        "_ = plt.legend(fontsize=20)\n",
        "plt.savefig(os.path.join(dirpath,f'figures/true_table_histogram.{figure_format}'),format=figure_format)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "40f20630",
      "metadata": {},
      "outputs": [],
      "source": [
        "str_to_table(list(true_table_histogram.keys())[0],dims=(I,J))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "a2dbea44",
      "metadata": {},
      "outputs": [],
      "source": [
        "ct.table"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "04c354ac",
      "metadata": {},
      "outputs": [],
      "source": [
        "np.exp(true_log_flows)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "9a67e607",
      "metadata": {},
      "outputs": [],
      "source": [
        "expected_flows"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "759daf2a",
      "metadata": {},
      "source": [
        "# Colsums sample inspection"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "60314c85",
      "metadata": {},
      "outputs": [],
      "source": [
        "# Count number of times true table was reconstructed\n",
        "# and build a histogram over table\n",
        "colsum_histogram = dict([(table_to_str(k), 0) for k in colsum_samples[burnin::colsum_steps]])\n",
        "for f in tqdm(colsum_samples[burnin::colsum_steps]):\n",
        "    # Append table count to histogram\n",
        "    colsum_histogram[table_to_str(f)] += 1\n",
        "    \n",
        "# Sort histogram by frequency\n",
        "# colsum_histogram = {k: v for k, v in sorted(colsum_histogram.items(), key=lambda item: item[0])}\n",
        "colsum_histogram = {k: v for k, v in sorted(colsum_histogram.items(), key=lambda item: -item[1])}\n",
        "n_colsum_samples = sum(colsum_histogram.values(), 0.0)\n",
        "colsum_probabilities = {k: v / n_colsum_samples for k, v in colsum_histogram.items()}\n",
        "\n",
        "if str_in_list(table_to_str(np.array(ct.true_colsums)),colsum_histogram.keys()):\n",
        "    print(f\"{int(100*colsum_histogram[table_to_str(np.array(ct.true_colsums))]/len(colsum_samples[burnin::colsum_steps]))}% of colsum samples matched true colsums\")\n",
        "    print('Matches',colsum_histogram[table_to_str(np.array(ct.true_colsums))])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "f5da0d64",
      "metadata": {},
      "outputs": [],
      "source": [
        "# Check whether true table is identified and in which order\n",
        "# Check how many tables have the right column sums\n",
        "true_colsum_index = -1\n",
        "for i,keyvalue in enumerate(colsum_histogram.items()):\n",
        "    # Monitor correct table samples\n",
        "    if keyvalue[0] == table_to_str(np.array(ct.true_colsums)):\n",
        "        true_colsum_index = i\n",
        "print(f'True colsum is the {true_colsum_index+1} most commonly sampled out of {len(colsum_histogram)} distinct colsums')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "be7d056c",
      "metadata": {},
      "outputs": [],
      "source": [
        "str_to_table(list(colsum_histogram.keys())[0],dims=(1,J))[0]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "ae0f9d12",
      "metadata": {},
      "outputs": [],
      "source": [
        "np.exp(true_log_flows).sum(axis=0)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "01bc794d",
      "metadata": {},
      "outputs": [],
      "source": [
        "ct.true_colsums"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "891586ce",
      "metadata": {},
      "outputs": [],
      "source": [
        "plt.figure(figsize=(20,10))\n",
        "plt.bar(range(len(colsum_histogram)), list(colsum_histogram.values()), align='center', label='samples')\n",
        "plt.bar(true_colsum_index, list(colsum_histogram.values())[true_colsum_index], align='center',color='red',label='true colsums')\n",
        "# _ = plt.xticks(range(len(colsum_histogram)), list(colsum_histogram.keys()),rotation=90)\n",
        "_ = plt.xlim(-1,len(colsum_histogram))\n",
        "_ = plt.ylabel('Frequency',fontsize=20)\n",
        "_ = plt.xlabel('Colsums string',fontsize=20)\n",
        "_ = plt.legend(fontsize=20)\n",
        "plt.savefig(os.path.join(dirpath,f'figures/colsum_histogram.{figure_format}'),format=figure_format)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "d1d9e129",
      "metadata": {},
      "source": [
        "# Intensity convergence"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "c4d6ef2f",
      "metadata": {},
      "outputs": [],
      "source": [
        "# Define sample sizes so that statistics will be compute every MCMC interval\n",
        "table_sample_step = 1\n",
        "table_burnin = 0\n",
        "table_chain_length = 20000\n",
        "maxN = int(min(table_burnin+table_chain_length,table_samples.shape[0]))\n",
        "table_sample_sizes = range(table_burnin+table_sample_step,maxN+table_sample_step,table_sample_step)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "569e9606",
      "metadata": {},
      "outputs": [],
      "source": [
        "lambda_sample_mean_error_l1_norms = np.zeros(len(table_sample_sizes))\n",
        "lambda_sample_mean_error_l2_norms = np.zeros(len(table_sample_sizes))\n",
        "for i,s in tqdm(enumerate(table_sample_sizes),total=len(table_sample_sizes)):\n",
        "    theta_running_mean_scaled = np.mean(theta_samples[table_burnin:s],axis=0)\n",
        "    theta_running_mean_scaled[1] *= sim.bmax\n",
        "    lambda_sample_mean_error_l1_norms[i] = relative_l1(\n",
        "                        tab0=true_log_flows,\n",
        "                        tab=np.mean(log_lambda_samples[table_burnin:s],axis=0)\n",
        "#         sim.log_intensity(np.mean(log_destination_attraction_samples[table_burnin:s],axis=0),theta_running_mean_scaled)\n",
        "    )\n",
        "    lambda_sample_mean_error_l2_norms[i] = relative_l2_norm(\n",
        "                        tab0=true_log_flows,\n",
        "                        tab=np.mean(log_lambda_samples[table_burnin:s],axis=0)\n",
        "#         sim.log_intensity(np.mean(log_destination_attraction_samples[table_burnin:s],axis=0),theta_running_mean_scaled)\n",
        "    )"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "8a3fabc6",
      "metadata": {},
      "outputs": [],
      "source": [
        "plt.figure(figsize=(7,5))\n",
        "plt.plot(table_sample_sizes,lambda_sample_mean_error_l1_norms)\n",
        "plt.xlabel('MCMC iteration',fontsize=16)\n",
        "plt.ylabel(r'Relative $L_1$ of $\\mathbb{E}[\\lambda]$',fontsize=16)\n",
        "plt.locator_params(axis='x', nbins=20)\n",
        "plt.axhline(y=0,color='red')\n",
        "plt.savefig(os.path.join(dirpath,f'figures/intensity_relative_l1_with_mcmc_iteration_chain_length_{table_chain_length}_{comment}.{figure_format}'),format=figure_format)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "6fb9ec18",
      "metadata": {},
      "outputs": [],
      "source": [
        "plt.figure(figsize=(7,5))\n",
        "plt.plot(table_sample_sizes,lambda_sample_mean_error_l2_norms)\n",
        "plt.xlabel('MCMC iteration',fontsize=16)\n",
        "plt.ylabel(r'Relative $L_2$ of $\\mathbb{E}[\\lambda]$',fontsize=16)\n",
        "plt.locator_params(axis='x', nbins=20)\n",
        "plt.axhline(y=0,color='red')\n",
        "plt.savefig(os.path.join(dirpath,f'figures/intensity_relative_l1_with_mcmc_iteration_chain_length_{table_chain_length}_{comment}.{figure_format}'),format=figure_format)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "bfd7e53f",
      "metadata": {},
      "source": [
        "# Table convergence\n",
        "\n",
        "### Check for convergence in probability of table mean estimator\n",
        "This checks if weak law of large numbers holds by ensuring that\n",
        "\n",
        "$$\\lim_{M\\to \\infty} |\\mathbf{\\bar{n}}^{(0:M)} - \\boldsymbol{\\lambda}|^p = 0$$\n",
        "\n",
        "for $p=1,2$. The norm is defined as follows:\n",
        "\n",
        "$$|\\mathbf{n}|^p = \\left( \\sum_{i,j}^{I,J} |n_{ij}|^p \\right)^{1/p}.$$\n",
        "\n",
        "The goal is to establish that \n",
        "$$\\mathbf{\\bar{n}}^{(0:i)} = \\frac{1}{M}\\sum_{m=1}^M \\mathbf{n}^{(m)} \\to \\left( \\frac{O_i \\lambda_{ij}}{\\sum_{l}^J \\lambda_{il}} \\right)_{i,j}^{I,J} = \\boldsymbol{\\lambda},$$\n",
        "i.e. that the estimator $\\mathbf{\\bar{n}}^{(0:i)}$ converges in probability to the ground truth mean."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "8f47df25",
      "metadata": {},
      "outputs": [],
      "source": [
        "# Define sample sizes so that statistics will be compute every MCMC interval\n",
        "table_sample_step = 1\n",
        "table_burnin = 0\n",
        "table_chain_length = 20000\n",
        "maxN = int(min(table_burnin+table_chain_length,table_samples.shape[0]))\n",
        "table_sample_sizes = range(table_burnin+table_sample_step,maxN+table_sample_step,table_sample_step)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "bf2cafa2",
      "metadata": {},
      "outputs": [],
      "source": [
        "table_sample_mean_error_l1_norms = np.zeros(len(table_sample_sizes))\n",
        "table_sample_mean_error_l2_norms = np.zeros(len(table_sample_sizes))\n",
        "for i,s in tqdm(enumerate(table_sample_sizes),total=len(table_sample_sizes)):\n",
        "    table_sample_mean_error_l1_norms[i] = relative_l1(\n",
        "                        tab0=np.exp(true_log_flows),\n",
        "                        tab=np.mean(table_samples[table_burnin:s],axis=0)\n",
        "    )\n",
        "    table_sample_mean_error_l2_norms[i] = relative_l2_norm(\n",
        "                        tab0=np.exp(true_log_flows),\n",
        "                        tab=np.mean(table_samples[table_burnin:s],axis=0)\n",
        "    )"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "3f9da6de",
      "metadata": {},
      "outputs": [],
      "source": [
        "plt.figure(figsize=(7,5))\n",
        "plt.plot(table_sample_sizes,table_sample_mean_error_l1_norms)\n",
        "plt.xlabel('MCMC iteration',fontsize=16)\n",
        "plt.ylabel(r'Relative $L_1$ of $\\mathbb{E}[\\mathbf{n}|\\mathbf{n}_{\\cdot,+}]$',fontsize=16)\n",
        "plt.locator_params(axis='x', nbins=20)\n",
        "plt.axhline(y=0,color='red')\n",
        "plt.savefig(os.path.join(dirpath,f'figures/expected_table_relative_l1_with_mcmc_iteration_chain_length_{table_chain_length}_{comment}.{figure_format}'),format=figure_format)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "0f8628f7",
      "metadata": {},
      "outputs": [],
      "source": [
        "plt.figure(figsize=(7,5))\n",
        "plt.plot(table_sample_sizes,table_sample_mean_error_l2_norms)\n",
        "plt.xlabel('MCMC iteration',fontsize=16)\n",
        "plt.ylabel(r'Relative $L_2$ of $\\mathbb{E}[\\mathbf{n}|\\mathbf{n}_{\\cdot,+}]$',fontsize=16)\n",
        "# plt.xticks(sample_sizes[::50])\n",
        "plt.locator_params(axis='x', nbins=20)\n",
        "plt.axhline(y=0,color='red')\n",
        "plt.savefig(os.path.join(dirpath,f'figures/expected_table_relative_l2_norm_with_mcmc_iteration_chain_length_{table_chain_length}_{comment}.{figure_format}'),format=figure_format)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "250f1567",
      "metadata": {},
      "source": [
        "### X,Theta Convergence\n",
        "## Import samples from different chains"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "a8e1d2df",
      "metadata": {},
      "outputs": [],
      "source": [
        "# Expertiment id\n",
        "experiment_id = 'synthetic_2x3_exp7'\n",
        "# Expertiment type\n",
        "experiment_type = 'JointTableSIMLatentLowNoiseMCMCConvergence'\n",
        "# Expertiment date\n",
        "date = '25_05_2022'\n",
        "\n",
        "# Define directory\n",
        "dirpath = f'../data/outputs/{experiment_id}_{experiment_type}_{date}/'\n",
        "# Define filepaths\n",
        "log_dest_attraction_filenames = os.path.join(dirpath,f'samples/log_destination_attraction_samples*.npy.gz')\n",
        "theta_filenames = os.path.join(dirpath,f'samples/theta_samples*.npy.gz')\n",
        "convergence_metadata_filename = os.path.join(dirpath,f'{experiment_id}_{experiment_type}_{date}_metadata.json')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "e0e9f19a",
      "metadata": {},
      "outputs": [],
      "source": [
        "with open(convergence_metadata_filename, 'r') as f:\n",
        "    convergence_metadata = json.load(f)\n",
        "    \n",
        "# Get number of chains\n",
        "M = convergence_metadata['M']"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "e43764b8",
      "metadata": {},
      "outputs": [],
      "source": [
        "log_destination_attraction_multiple_samples = []\n",
        "for file in sorted(glob.glob(log_dest_attraction_filenames)):\n",
        "    # Load files into memory\n",
        "    s = read_npy(file)\n",
        "    log_destination_attraction_multiple_samples.append(s)\n",
        "    \n",
        "theta_multiple_samples = []\n",
        "for file in sorted(glob.glob(theta_filenames)):\n",
        "    # Load files into memory\n",
        "    s = read_npy(file)\n",
        "    theta_multiple_samples.append(s)\n",
        "    \n",
        "theta_multiple_samples = np.array(theta_multiple_samples)\n",
        "log_destination_attraction_multiple_samples = np.array(log_destination_attraction_multiple_samples)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "57f7e2e3",
      "metadata": {},
      "source": [
        "## Trace plots for different chains"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "78312fca",
      "metadata": {},
      "outputs": [],
      "source": [
        "chain_index = 8\n",
        "fig,axs = plt.subplots(1,2,figsize=(20,10))\n",
        "\n",
        "axs[0].plot(theta_multiple_samples[chain_index,burnin:, 0],label='samples')\n",
        "axs[0].set_ylabel(r'$\\alpha$',fontsize=18,rotation=0,labelpad=7)\n",
        "axs[0].set_xlabel('MCMC samples',fontsize=18,labelpad=7)\n",
        "if hasattr(sim,'alpha_true'):\n",
        "    axs[0].axhline(y=sim.alpha_true, color='black', linestyle='-',label='true')\n",
        "axs[0].axhline(y=np.mean(theta_multiple_samples[chain_index,burnin:, 0]),color='lime',label=r'$\\mu$')\n",
        "axs[0].set_ylim(0,2.0)\n",
        "axs[0].legend()\n",
        "\n",
        "axs[1].plot(theta_multiple_samples[chain_index,burnin:, 1])\n",
        "axs[1].set_ylabel(r'$\\beta$',fontsize=18,rotation=0,labelpad=7)\n",
        "axs[1].set_xlabel('MCMC samples',fontsize=18,labelpad=7)\n",
        "if hasattr(sim,'beta_true'):\n",
        "    axs[1].axhline(y=sim.beta_true, color='black', linestyle='-',label='true')\n",
        "axs[1].axhline(y=np.mean(theta_multiple_samples[chain_index,burnin:, 1]),color='lime',label=r'$\\mu$')\n",
        "axs[1].set_ylim(0,2.0)\n",
        "axs[1].legend()\n",
        "\n",
        "fig.suptitle(fr'{experiment_type}',fontsize=20)\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "77685f9a",
      "metadata": {},
      "outputs": [],
      "source": [
        "fig,axs = plt.subplots(1,J,figsize=(20,10))\n",
        "relative_noise = np.sqrt(sim.noise_var)/np.log(sim.dims[1])\n",
        "relative_noise_percentage = round(100*relative_noise)\n",
        "upper_bound = sim.log_destination_attraction + np.log((1.0+relative_noise_percentage/100))\n",
        "lower_bound = sim.log_destination_attraction - np.log((1.0+relative_noise_percentage/100))\n",
        "for j in range(J):\n",
        "    axs[j].plot(log_destination_attraction_multiple_samples[chain_index,burnin:, j])\n",
        "    axs[j].set_ylabel(fr'$x_{j}$',fontsize=18,rotation=0,labelpad=7)\n",
        "    axs[j].set_xlabel('MCMC samples',fontsize=18,labelpad=7)\n",
        "    axs[j].axhline(y=np.mean(log_destination_attraction_multiple_samples[chain_index,burnin:],axis=0)[j], color='lime', linestyle='-',label='$\\mu$')\n",
        "    axs[j].axhline(y=sim.log_destination_attraction[j], color='r', linestyle='-',label='data')\n",
        "#     axs[j].axhline(y=sim.log_true_destination_attraction[j], color='black', linestyle='-',label='generated')\n",
        "    axs[j].axhline(y=upper_bound[j], color='r', linestyle='--',label=f'data + {relative_noise_percentage}%')\n",
        "    axs[j].axhline(y=lower_bound[j], color='r', linestyle='--',label=f'data - {relative_noise_percentage}%')\n",
        "    axs[j].legend()\n",
        "fig.suptitle(fr'{experiment_type}',fontsize=20)\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "e4d14743",
      "metadata": {},
      "outputs": [],
      "source": [
        "def gelman_rubin_criterion(samples,burnin:int,step:int=1,r_critical:float=1.1,prints:bool=True):\n",
        "        \n",
        "    # Convert to numpy\n",
        "    samples = np.array(samples)\n",
        "    \n",
        "    # Get number of chain iterations and number of chains\n",
        "    m,n,p = np.shape(samples)\n",
        "    \n",
        "    # Create list of possible burnin times\n",
        "    possible_lengths = list(range(burnin+step,n,step))\n",
        "\n",
        "    if prints: print(f'Gelman Rubin convergence criterion with M = {m}, N = {n-burnin}, P = {p}')\n",
        "\n",
        "    r_stats = np.ones((len(possible_lengths),p))*1e9\n",
        "    converged_chain_length = 0\n",
        "    # Loop over possible burnins\n",
        "    for i,chain_length in enumerate(possible_lengths):\n",
        "        if prints:\n",
        "            print(f'Checking convergence with chain length = {chain_length-burnin}')\n",
        "\n",
        "        # Calculate between-chain variance\n",
        "        B_over_m = np.sum([(np.mean(samples[:,burnin:(chain_length),:], axis=1)[j,:] - np.mean(samples[:,burnin:(chain_length),:],axis=(0,1)))**2 for j in range(m)],axis=0) / (m - 1)\n",
        "    \n",
        "        # Calculate within-chain variances\n",
        "        W = np.sum([(samples[i,burnin:(chain_length)] - xbar) ** 2 for i,xbar in enumerate(np.mean(samples[:,burnin:(chain_length)],1))],axis=(0,1)) / (m * (chain_length-burnin - 1))\n",
        "    \n",
        "        # (over) estimate of variance\n",
        "        s2 = W * (chain_length-burnin-1) / (chain_length-burnin) + B_over_m\n",
        "\n",
        "        # Pooled posterior variance estimate\n",
        "        V = s2 + B_over_m / m\n",
        "\n",
        "        # Calculate PSRF\n",
        "        r_stat = V / W\n",
        "        r_stats[i] = r_stat\n",
        "\n",
        "        # Print if chains have converged\n",
        "        if all(r_stat < r_critical):\n",
        "            if prints:\n",
        "                print(r'Vanilla MCMC chains have converged!')\n",
        "                print(pd.DataFrame(r_stat))\n",
        "                print(f'Chain length: {chain_length-burnin}')\n",
        "                print(f'Burnin: {burnin}')\n",
        "                prints = False\n",
        "            converged_chain_length = chain_length-burnin\n",
        "\n",
        "    if any(r_stat >= r_critical):\n",
        "        print(r'Vanilla MCMC chains have NOT converged ...')\n",
        "        print(pd.DataFrame(r_stat))\n",
        "        \n",
        "    return r_stats, converged_chain_length\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "4f005516",
      "metadata": {},
      "outputs": [],
      "source": [
        "# Define burnin and chain length step size\n",
        "burnin_period = 2000\n",
        "chain_length_step_size = 1000\n",
        "N = theta_multiple_samples.shape[1]\n",
        "r_critical_value = 1.1\n",
        "maxN = min(burnin+8000,N)\n",
        "# Get chain lengths\n",
        "chain_lengths = np.array(list(range(burnin_period+chain_length_step_size,maxN,chain_length_step_size)))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "d73cc731",
      "metadata": {},
      "outputs": [],
      "source": [
        "theta_r_stats,theta_chain_length = gelman_rubin_criterion(\n",
        "                                        theta_multiple_samples[:,:maxN,:],\n",
        "                                        burnin=burnin_period,\n",
        "                                        step=chain_length_step_size,\n",
        "                                        r_critical=r_critical_value\n",
        "                                    )"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "d3bb698b",
      "metadata": {},
      "outputs": [],
      "source": [
        "destination_attraction_r_stats,destination_attraction_chain_length = gelman_rubin_criterion(\n",
        "                                                                        log_destination_attraction_multiple_samples[:,:maxN,:],\n",
        "                                                                        burnin=burnin_period,\n",
        "                                                                        step=chain_length_step_size,\n",
        "                                                                        r_critical=r_critical_value\n",
        "                                                                    )"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "12897121",
      "metadata": {},
      "source": [
        "# Plot R statitistic with chain length"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "103fc750",
      "metadata": {},
      "outputs": [],
      "source": [
        "plt.figure(figsize=(15,10))\n",
        "for i in range(np.shape(theta_r_stats)[1]):\n",
        "    plt.plot(chain_lengths-burnin_period,theta_r_stats[:,i],label=fr'${sim.parameter_names[i]}$')\n",
        "plt.plot(chain_lengths-burnin_period,np.ones(len(chain_lengths))*r_critical_value,label='$R_{critical}$',color='red')\n",
        "plt.ylabel(r'$R$ statistic',fontsize=15)\n",
        "plt.xlabel('MCMC chain length',fontsize=15)\n",
        "plt.locator_params(axis='x', nbins=20)\n",
        "# plt.xticks((chain_lengths-burnin_period)[::2],(chain_lengths-burnin_period)[::2])\n",
        "plt.legend(frameon=False,prop={'size': 15})\n",
        "plt.savefig(os.path.join(dirpath,f'figures/r_statistic_parameters_vs_mcmc_chain_length.{figure_format}'),format=figure_format)\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "83610f91",
      "metadata": {},
      "outputs": [],
      "source": [
        "plt.figure(figsize=(15,10))\n",
        "for i in range(np.shape(destination_attraction_r_stats)[1]):\n",
        "    plt.plot(chain_lengths-burnin_period,destination_attraction_r_stats[:,i],label=fr'${sim.parameter_names[i]}$')\n",
        "plt.plot(chain_lengths-burnin_period,np.ones(len(chain_lengths))*r_critical_value,label='$R_{critical}$',color='red')\n",
        "plt.ylabel(r'$R$ statistic',fontsize=15)\n",
        "plt.xlabel('MCMC chain length',fontsize=15)\n",
        "plt.locator_params(axis='x', nbins=20)\n",
        "# plt.xticks((chain_lengths-burnin_period)[::2],(chain_lengths-burnin_period)[::2])\n",
        "plt.legend(frameon=False,prop={'size': 15})\n",
        "plt.savefig(os.path.join(dirpath,f'figures/r_statistic_log_destination_attraction_vs_mcmc_chain_length.{figure_format}'),format=figure_format)\n",
        "plt.show()"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "multiresticodm",
      "language": "python",
      "name": "multiresticodm"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.5"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}

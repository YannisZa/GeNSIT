{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import h5py as h5\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "from copy import deepcopy\n",
    "\n",
    "\n",
    "from multiresticodm.config import Config\n",
    "from multiresticodm.inputs import Inputs\n",
    "from multiresticodm.outputs import Outputs\n",
    "from multiresticodm.utils.misc_utils import *\n",
    "from multiresticodm.utils.math_utils import *\n",
    "from multiresticodm.contingency_table import instantiate_ct\n",
    "from multiresticodm.utils.probability_utils import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "\n",
    "# AUTO RELOAD EXTERNAL MODULES\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get important paths\n",
    "experiment_dir = '../data/outputs/cambridge_work_commuter_lsoas_to_msoas/exp1/JointTableSIM_MCMC_SweepedNoise_16_05_2023_20_09_04/'\n",
    "config_path = os.path.join(experiment_dir,'config.json')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Output processing settings\n",
    "settings = {\n",
    "    \"logging_mode\": \"INFO\",\n",
    "    \"coordinate_slice\": [],\n",
    "        # \"da.loss_name.isin([str(['dest_attraction_ts_likelihood_loss']),str(['dest_attraction_ts_likelihood_loss', 'table_likelihood_loss'])])\",\n",
    "    \"metadata_keys\":[],\n",
    "    \"burnin_thinning_trimming\": [{'iter': {\"burnin\":10000, \"thinning\":100, \"trimming\":1000}}],\n",
    "    \"n_workers\": 1,\n",
    "    \"filename_ending\":\"test\",\n",
    "    \"sample\":[\"table\",\"intensity\"],\n",
    "    \"force_reload\":True\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "outputs = Outputs(\n",
    "    config = config_path,\n",
    "    settings = settings,\n",
    "    base_dir = experiment_dir,\n",
    "    inputs = None,\n",
    "    slice = True\n",
    ")\n",
    "# Silence outputs\n",
    "outputs.logger.setLevels(console_level='EMPTY')\n",
    "# Collect outputs from folder\n",
    "outputs.load()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def validate_tables(out):\n",
    "    out.inputs.cast_from_xarray()\n",
    "    ct = instantiate_ct(\n",
    "        config = out.config,\n",
    "        **out.inputs.data_vars(),\n",
    "        level = 'EMPTY'\n",
    "    )\n",
    "    samples = out.get_sample('table')\n",
    "    print('axes constraints',ct.constraints['constrained_axes'])\n",
    "    print('cell constraints',len(ct.constraints['cells']))\n",
    "    tables_admissible = all([ct.table_admissible(torch.tensor(tab.values.squeeze())) for _,tab in samples.groupby('id')])\n",
    "    print('Tables admissible',tables_admissible)\n",
    "    if not tables_admissible:\n",
    "        print('Tables margins admissible',any([ct.table_margins_admissible(torch.tensor(tab.values.squeeze())) for _,tab in samples.groupby('id')]))\n",
    "        print('Tables cells admissible',all([ct.table_cells_admissible(torch.tensor(tab.values.squeeze())) for _,tab in samples.groupby('id')]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = []\n",
    "for i in tqdm(\n",
    "    range(len(outputs.data)),\n",
    "    leave=True,\n",
    "    disable=True,\n",
    "    desc='Computing validation metrics'\n",
    "):\n",
    "    print(f\"{i+1}/{len(outputs.data)}\") \n",
    "    sweep_outputs = outputs.get(i)\n",
    "    sweep_outputs.inputs = Inputs(\n",
    "        config = sweep_outputs.config,\n",
    "        synthetic_data = False,\n",
    "        logger = outputs.logger\n",
    "    )\n",
    "\n",
    "    mean_intensity = sweep_outputs.compute_statistic(\n",
    "        data = sweep_outputs.get_sample('intensity'),\n",
    "        sample_name = 'intensity',\n",
    "        statistic = 'signedmean',\n",
    "        dim = ['id']\n",
    "    )\n",
    "    intensity_srmse = srmse(\n",
    "        prediction = mean_intensity,\n",
    "        ground_truth = outputs.get(0).get_sample('ground_truth_table').astype('float32')\n",
    "    )\n",
    "    # Create a data row\n",
    "    datum = dict(zip(\n",
    "        outputs.config.sweep_param_names,\n",
    "        mean_intensity['sweep'].values[0]\n",
    "    ))\n",
    "    print('sweep',{k:v for k,v in datum.items() if k not in ['covariance','to_learn']})\n",
    "    datum['intensity_srmse'] = intensity_srmse.values[0]\n",
    "    \n",
    "    try:\n",
    "        mean_table = sweep_outputs.compute_statistic(\n",
    "            data = sweep_outputs.get_sample('table'),\n",
    "            sample_name = 'table',\n",
    "            statistic = 'mean',\n",
    "            dim = ['id']\n",
    "        )\n",
    "        table_srmse = srmse(\n",
    "            prediction = mean_table,\n",
    "            ground_truth = outputs.get(0).get_sample('ground_truth_table').astype('float32')\n",
    "        )\n",
    "        datum['table_srmse'] = table_srmse.values[0]\n",
    "\n",
    "        \n",
    "    except:\n",
    "        pass\n",
    "    data.append(datum)\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame.from_records(data)\n",
    "df.drop(columns=['covariance','to_learn','axes','cells'],inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "root_path = '/home/iz230/MultiResTICODM/data/outputs/cambridge_work_commuter_lsoas_to_msoas/exp1/JointTableSIM_MCMC_SweepedNoise_16_05_2023_20_09_04/samples/'\n",
    "relative_path = os.path.relpath(root_path,os.getcwd())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Output processing settings\n",
    "settings = {\n",
    "    \"logging_mode\": \"INFO\",\n",
    "    \"coordinate_slice\": [],\n",
    "        # \"da.loss_name.isin([str(['dest_attraction_ts_likelihood_loss']),str(['dest_attraction_ts_likelihood_loss', 'table_likelihood_loss'])])\",\n",
    "    \"metadata_keys\":[],\n",
    "    \"burnin_thinning_trimming\": [{'iter': {\"burnin\":10000, \"thinning\":100, \"trimming\":1000}}],\n",
    "    \"n_workers\": 1,\n",
    "    \"filename_ending\":\"test\",\n",
    "    \"sample\":[\"table\",\"intensity\"],\n",
    "    \"force_reload\":True\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "current_sweep_outputs = Outputs(\n",
    "    config = '../data/outputs/cambridge_work_commuter_lsoas_to_msoas/exp1/JointTableSIM_MCMC_SweepedNoise_16_05_2023_20_09_04/samples/sigma_high/title__total_intensity_row_table_constrained/',\n",
    "    settings = settings,\n",
    "    inputs = None,\n",
    "    slice = True\n",
    ")\n",
    "current_sweep_outputs.load()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "mrticodm",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

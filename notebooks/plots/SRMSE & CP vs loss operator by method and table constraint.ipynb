{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c76b8620",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import re\n",
    "import subprocess\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib as mpl\n",
    "mpl.use('ps')\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from copy import deepcopy\n",
    "from tqdm.auto import tqdm\n",
    "from collections import defaultdict\n",
    "from matplotlib.lines import Line2D\n",
    "from matplotlib.ticker import MultipleLocator\n",
    "from matplotlib.legend_handler import HandlerTuple\n",
    "# from IPython.core.display import display, HTML\n",
    "\n",
    "from gensit.config import Config\n",
    "from gensit.inputs import Inputs\n",
    "from gensit.outputs import Outputs,OutputSummary\n",
    "from gensit.utils.misc_utils import *\n",
    "from gensit.utils.math_utils import *\n",
    "from gensit.utils.probability_utils import *\n",
    "from gensit.static.plot_variables import LATEX_RC_PARAMETERS, COLOR_NAMES, PLOT_VARIABLES"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b718b815",
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "\n",
    "# AUTO RELOAD EXTERNAL MODULES\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83599fa1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# LaTeX font configuration\n",
    "mpl.rcParams.update(LATEX_RC_PARAMETERS)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8785d438",
   "metadata": {},
   "source": [
    "# SRMSE & CP vs loss operator by sigma and table constraint\n",
    "variable = table\n",
    "\n",
    "sigma = low,high,learned\n",
    "\n",
    "constraints = total,rowsums,doubly,doubly_10percent_cells,doubly_20percent_cells"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ddac5e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "datapath = \"../../data/outputs/cambridge/exp3/paper_figures/figure4_rerun_v2/loss_function_validation_all_odms\"\n",
    "\n",
    "\n",
    "# datapath = \"../../data/outputs/cambridge/exp3/paper_figures/figure4_v1/loss_function_validation_tractable_odms_label_sigma&title_marker_sigma_markersize_table_coverage_probability_size_linewidth_1.0_colour_title_opacity_1.0_hatchopacity_1.0\"\n",
    "\n",
    "# datapath = \"../../data/outputs/cambridge/exp3/paper_figures/figure4_v1/loss_function_validation_intractable_odms_label_sigma&title_marker_sigma_markersize_table_coverage_probability_size_linewidth_1.0_colour_title_opacity_1.0_hatchopacity_1.0\"\n",
    "\n",
    "# loss_function_validation_intractable_odms_label_sigma&title_marker_sigma_markersize_table_coverage_probability_size_linewidth_1.0_colour_title_opacity_1.0_hatchopacity_1.0\n",
    "# loss_function_validation_tractable_odms_label_sigma&title_marker_sigma_markersize_table_coverage_probability_size_linewidth_1.0_colour_title_opacity_1.0_hatchopacity_1.0\n",
    "\n",
    "\n",
    "outputbasepath =\"../../data/outputs/cambridge/exp3/paper_figures/figure4_v2/\"\n",
    "\n",
    "figuretitle = \"_vs_loss_operator_by_constraints_method_sigma\"\n",
    "\n",
    "sweep_data = {\n",
    "    \"|total|\": [\n",
    "        \"$\\sigma = 0.014$, $\\mytabletotal$\",\n",
    "        \"$\\sigma = 0.141$, $\\mytabletotal$\",\n",
    "        r\"$\\sigma = \\text{learned}$, $\\mytabletotal$\"\n",
    "    ],\n",
    "    \"|colsums|\": [\n",
    "        \"$\\sigma = 0.014$, $\\mytablerowsums$\",\n",
    "        \"$\\sigma = 0.141$, $\\mytablerowsums$\",\n",
    "        r\"$\\sigma = \\text{learned}$, $\\mytablerowsums$\"\n",
    "    ],\n",
    "    \"|doubly|\": [\n",
    "        \"$\\sigma = 0.014$, $\\mytablerowsums,\\mytablecolsums$\",\n",
    "        \"$\\sigma = 0.141$, $\\mytablerowsums,\\mytablecolsums$\",\n",
    "        r\"$\\sigma = \\text{learned}$, $\\mytablerowsums,\\mytablecolsums$\"\n",
    "    ],\n",
    "    \"|doubly_10percent_cells|\": [\n",
    "        r\"$\\sigma = 0.014$, $\\mytablerowsums,\\mytablecolsums,\\mytablecells{_1}$\",\n",
    "        r\"$\\sigma = 0.141$, $\\mytablerowsums,\\mytablecolsums,\\mytablecells{_1}$\",\n",
    "        r\"$\\sigma = \\text{learned}$, $\\mytablerowsums,\\mytablecolsums,\\mytablecells{_1}$\"\n",
    "    ],\n",
    "    \"|doubly_20percent_cells|\": [\n",
    "        r\"$\\sigma = 0.014$, $\\mytablerowsums,\\mytablecolsums,\\mytablecells{_2}$\",\n",
    "        r\"$\\sigma = 0.141$, $\\mytablerowsums,\\mytablecolsums,\\mytablecells{_2}$\",\n",
    "        r\"$\\sigma = \\text{learned}$, $\\mytablerowsums,\\mytablecolsums,\\mytablecells{_2}$\"\n",
    "    ]\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "id": "7aff3078",
   "metadata": {},
   "outputs": [],
   "source": [
    "fontsize = 14\n",
    "\n",
    "SIGMA_MARKERS = {\n",
    "    \"$\\sigma = 0.014$\":\"v\",\n",
    "    \"$\\sigma = 0.141$\":\"^\",\n",
    "    r\"$\\sigma = \\text{learned}$\":\">\"\n",
    "} \n",
    "SIGMA_COLORS = {\n",
    "    \"$\\sigma = 0.014$\":\"#A2CFFE\",\n",
    "    \"$\\sigma = 0.141$\":\"#9B59B6\",\n",
    "    r\"$\\sigma = \\text{learned}$\":\"#2ECC40\"\n",
    "}\n",
    "\n",
    "# TABLE_CONSTRAINT_COLORS = {\n",
    "#     \"$\\mytabletotal$\":COLOR_NAMES[\"tab20b_purple\"],\n",
    "#     \"$\\mytablecolsums$\":COLOR_NAMES[\"tab20b_green\"],\n",
    "#     \"$\\mytablecolsums,\\mytablerowsums$\":COLOR_NAMES[\"tab20b_orange\"],\n",
    "#     \"$\\mytablecolsums,\\mytablerowsums,\\mytablecells{_1}$\":COLOR_NAMES[\"tab20b_red\"],\n",
    "#     \"$\\mytablecolsums,\\mytablerowsums,\\mytablecells{_2}$\":COLOR_NAMES[\"tab20c_blue\"],\n",
    "# }\n",
    "\n",
    "KEEP_KEYS = [\"loss_operator\",\"srmse\",\"cp\",\"sigma\",\"table_constraints\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "id": "b2dff6b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def myplot(data,output_path,groups,x_label,y_label):\n",
    "    fig,ax = plt.subplots()#figsize=(10,15)\n",
    "    # ax.set_box_aspect(1)\n",
    "\n",
    "    num_data = np.shape(data[y_label])[0]\n",
    "    \n",
    "    # Get unique elements without changing their order of appearance\n",
    "    xlabels = list(dict.fromkeys(data[x_label]))\n",
    "    x = np.arange(1,len(xlabels)*5,5)\n",
    "    xlabel_dict = dict(zip(xlabels,x))\n",
    "\n",
    "    # Create a defaultdict that defaults to another defaultdict\n",
    "    data_tree = defaultdict(lambda: defaultdict())\n",
    "    for i in range(num_data):\n",
    "        _ = ax.scatter(\n",
    "            xlabel_dict[data[x_label][i]],\n",
    "            data[y_label][i],\n",
    "            linewidth = 1.0,\n",
    "            alpha=1.0,\n",
    "            c = SIGMA_COLORS[data['sigma'][i]],\n",
    "            marker = SIGMA_MARKERS[data['sigma'][i]],\n",
    "        )\n",
    "        # print(' > '.join([data[g][i] for g in groups]))\n",
    "        add_leaf(data_tree, [data[g][i] for g in groups], {k:v[i] for k,v in data.items() if k in KEEP_KEYS})\n",
    "        \n",
    "    # Collect paths and leaf data\n",
    "    leaf_data = traverse_tree(data_tree,KEEP_KEYS)\n",
    "\n",
    "    # Print out the collected paths and leaf node data\n",
    "    for path, leaf in leaf_data:\n",
    "        # print(f\"Path: {' -> '.join(path)} Sigma: {list(set(leaf['sigma']))}\")\n",
    "        # print(json.dumps({k:v for k,v in leaf.items() if k in ['iteration_ensemble','srmse']},indent=2))\n",
    "        _ = ax.plot(\n",
    "            [xlabel_dict[v] for v in leaf[x_label]],\n",
    "            leaf[y_label],\n",
    "            linewidth = 1.0,\n",
    "            linestyle = \"solid\",\n",
    "            c = SIGMA_COLORS[leaf['sigma'][0]],\n",
    "            marker = SIGMA_MARKERS[leaf['sigma'][0]],\n",
    "        )\n",
    "\n",
    "    ax.tick_params(labelsize=fontsize)\n",
    "    ax.set_xticks(x)\n",
    "    ax.set_xticklabels(xlabels,rotation=40, ha=\"right\")\n",
    "    ax.xaxis.set_major_locator(mpl.ticker.FixedLocator(x))\n",
    "    \n",
    "    plt.xlabel(x_label.replace('_',' ').capitalize(),fontsize=fontsize)\n",
    "    plt.ylabel(y_label.upper(),fontsize=fontsize)\n",
    "\n",
    "    if y_label == 'cp':\n",
    "        plt.ylim(0,100)\n",
    "\n",
    "    legend_tree = dict()\n",
    "    # Adding custom legend entries: one for each noise regime with all variations\n",
    "    for noise,marker in SIGMA_MARKERS.items():\n",
    "        style = Line2D(\n",
    "            xdata=[0,100],\n",
    "            ydata=[0,0], \n",
    "            color=SIGMA_COLORS[noise], \n",
    "            marker=marker, \n",
    "            linestyle=\"solid\", \n",
    "            label=noise,\n",
    "            linewidth=1,\n",
    "            markersize=5\n",
    "        )\n",
    "        legend_tree[noise] = style\n",
    "\n",
    "    # Manually create legend handles using the Line2D objects\n",
    "    handles,labels = [],[]\n",
    "    for label, lines in legend_tree.items():\n",
    "        handles.append(lines)\n",
    "        labels.append(label)\n",
    "\n",
    "    # Add the custom legend (only use one label per group)\n",
    "    plt.legend(\n",
    "        handles=handles, \n",
    "        labels=labels, \n",
    "        # handler_map={tuple: HandlerTuple(ndivide=None)},\n",
    "        handlelength=2,\n",
    "        handleheight=0.5,\n",
    "        markerscale=1,\n",
    "        loc='best', \n",
    "        fontsize=9, \n",
    "        frameon=True,\n",
    "        ncol=1,\n",
    "    )\n",
    "\n",
    "    # fig.tight_layout(rect=(0, 0, 0.7, 1.1))\n",
    "    # fig.tight_layout()\n",
    "\n",
    "    # plt.show()\n",
    "    makedir(os.path.dirname(output_path))\n",
    "    write_figure(\n",
    "        fig,\n",
    "        output_path,\n",
    "        figure_format='ps',\n",
    "        pad_inches=0.0,\n",
    "        bbox_inches='tight'\n",
    "    )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "id": "809b0293",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/5 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "|total| TOTAL 30\n",
      "Loss operator 10\n",
      "Table constraints 1\n",
      "Sigma 3\n",
      "\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The PostScript backend does not support transparency; partially transparent artists will be rendered opaque.\n",
      "The PostScript backend does not support transparency; partially transparent artists will be rendered opaque.\n",
      " 20%|██        | 1/5 [00:04<00:18,  4.68s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "|colsums| TOTAL 30\n",
      "Loss operator 10\n",
      "Table constraints 1\n",
      "Sigma 3\n",
      "\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The PostScript backend does not support transparency; partially transparent artists will be rendered opaque.\n",
      "The PostScript backend does not support transparency; partially transparent artists will be rendered opaque.\n",
      " 40%|████      | 2/5 [00:09<00:14,  4.72s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "|doubly| TOTAL 30\n",
      "Loss operator 10\n",
      "Table constraints 1\n",
      "Sigma 3\n",
      "\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The PostScript backend does not support transparency; partially transparent artists will be rendered opaque.\n",
      "The PostScript backend does not support transparency; partially transparent artists will be rendered opaque.\n",
      " 60%|██████    | 3/5 [00:14<00:09,  4.76s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "|doubly_10percent_cells| TOTAL 30\n",
      "Loss operator 10\n",
      "Table constraints 1\n",
      "Sigma 3\n",
      "\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The PostScript backend does not support transparency; partially transparent artists will be rendered opaque.\n",
      "The PostScript backend does not support transparency; partially transparent artists will be rendered opaque.\n",
      " 80%|████████  | 4/5 [00:19<00:04,  4.86s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "|doubly_20percent_cells| TOTAL 30\n",
      "Loss operator 10\n",
      "Table constraints 1\n",
      "Sigma 3\n",
      "\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The PostScript backend does not support transparency; partially transparent artists will be rendered opaque.\n",
      "The PostScript backend does not support transparency; partially transparent artists will be rendered opaque.\n",
      "100%|██████████| 5/5 [00:24<00:00,  4.81s/it]\n"
     ]
    }
   ],
   "source": [
    "group_keys = ['sigma']\n",
    "sort_keys = ['loss_operator']\n",
    "\n",
    "for sweep_id, slice_vals in tqdm(sweep_data.items(),total=len(sweep_data.keys())):\n",
    "    srmseoutputpath = outputbasepath+\"srmse\"+figuretitle+sweep_id\n",
    "    cpoutputpath = outputbasepath+\"cp\"+figuretitle+sweep_id\n",
    "\n",
    "    data = read_json(datapath+'_data.json')\n",
    "\n",
    "    slice_key = 'label'\n",
    "    slice_index = []\n",
    "    for i,v in enumerate(data[slice_key]):\n",
    "        if any([v == sv for sv in slice_vals]):\n",
    "            # print(v)\n",
    "            slice_index.append(i)\n",
    "    \n",
    "    assert slice_index\n",
    "\n",
    "    data_slice = deepcopy(data)\n",
    "    IGNORED_COLUMNS = ['outputs','x_group','y_group','z_group','annotate','hatch','x_id','y_id','z_id','z']\n",
    "\n",
    "    dropped_keys = []\n",
    "    for k in data_slice.keys():\n",
    "        if k not in IGNORED_COLUMNS:\n",
    "            data_slice[k] = np.array(data_slice[k])[slice_index].tolist()\n",
    "        else:\n",
    "            dropped_keys.append(k)\n",
    "    \n",
    "    data_slice['loss_operator'] = np.array(data_slice['x'])[:,0].tolist()\n",
    "    data_slice['srmse'] = np.array(data_slice['y'])[:,0].tolist()\n",
    "    data_slice['cp'] = (100*np.array(data_slice['marker_size'])).tolist()\n",
    "    \n",
    "    # Pattern to match LaTeX-style expressions\n",
    "    label_pattern = r'\\$(.*?)\\$'\n",
    "    # Separate into two lists\n",
    "    data_slice['sigma'] = []\n",
    "    data_slice['table_constraints'] = []\n",
    "\n",
    "    for item in data_slice['label']:\n",
    "        matches = re.findall(label_pattern, item)\n",
    "        if len(matches) == 2:\n",
    "            data_slice['sigma'].append(f\"${matches[0]}$\")\n",
    "            data_slice['table_constraints'].append(f\"${matches[1]}$\")\n",
    "    \n",
    "    for k in dropped_keys+['x','y','colour']:\n",
    "        del data_slice[k]\n",
    "\n",
    "    # for k,v in data_slice.items():\n",
    "    #     if len(np.shape(v)) > 0 and np.shape(v)[0] > 0:\n",
    "    #         print(k,np.shape(v))\n",
    "\n",
    "    # Sort all lists based on the values of the selected key\n",
    "    sorted_indices = sorted(range(len(data_slice['loss_operator'])), key=lambda i: tuple([data_slice[k][i] for k in sort_keys]))\n",
    "\n",
    "    # Reorder each list in the dictionary\n",
    "    for k, v in data_slice.items():\n",
    "        try:\n",
    "            data_slice[k] = np.array([v[i] for i in sorted_indices])\n",
    "        except:\n",
    "            pass\n",
    "\n",
    "    unique_data = set()\n",
    "    for m in range(len(data_slice['loss_operator'])):\n",
    "        new_data = data_slice['loss_operator'][m] + \"\\n\" + data_slice['table_constraints'][m]+ \"\\n\"+ data_slice['sigma'][m]\n",
    "        if new_data in unique_data:\n",
    "            print(new_data)\n",
    "        unique_data.add(new_data)\n",
    "    \n",
    "    print(f\"{sweep_id} TOTAL\",len(unique_data))\n",
    "    print(\"Loss operator\",len(set(data_slice['loss_operator'])))\n",
    "    print(\"Table constraints\",len(set(data_slice['table_constraints'])))\n",
    "    print(\"Sigma\",len(set(data_slice['sigma'])))\n",
    "    print('\\n\\n')\n",
    "    # print(sweep_id,data_slice['cp'].shape[0])\n",
    "    # print(set(data_slice['sigma']))\n",
    "    # print(set(data_slice['table_constraints']))\n",
    "    # print('LOSS',len(set(data_slice['loss_operator'])))\n",
    "    \n",
    "    myplot(\n",
    "        data=data_slice,\n",
    "        output_path=srmseoutputpath,\n",
    "        groups=group_keys,\n",
    "        x_label='loss_operator',\n",
    "        y_label='srmse'\n",
    "    )\n",
    "    myplot(\n",
    "        data=data_slice,\n",
    "        output_path=cpoutputpath,\n",
    "        groups=group_keys,\n",
    "        x_label='loss_operator',\n",
    "        y_label='cp'\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a558681",
   "metadata": {},
   "outputs": [],
   "source": [
    "# data = read_json(datapath+'_data.json')\n",
    "\n",
    "# all_sweep_vals = []\n",
    "# for val in sweep_data.values():\n",
    "#     all_sweep_vals += val\n",
    "\n",
    "# ignore_index = set()\n",
    "# for i,v in enumerate(np.array(data['x'])[:,0]):\n",
    "#     if v == \"$\\\\lossoperator\\\\left( \\\\myintensity \\\\; ; \\\\; \\\\obsdata^{\\\\myintensityoned} \\\\right)$\" or \\\n",
    "#         v == \"$\\\\lossoperator\\\\left(\\\\mytable \\\\; ; \\\\; \\\\obsdata^{\\\\mytableoned} \\\\right)$\" or \\\n",
    "#         v == '$\\\\lossoperator\\\\left(\\\\mylogdestattr, \\\\mytable, \\\\myintensity \\\\; ; \\\\; \\\\obsdata, \\\\boldsymbol{\\\\nu} \\\\right)$' or \\\n",
    "#         v == \"$\\\\lossoperator\\\\left( \\\\myintensity \\\\; ; \\\\; \\\\obsdata^{\\\\myintensityoned} \\\\right)$\" or \\\n",
    "#         v == \"$\\\\lossoperator\\\\left(\\\\mytable \\\\; ; \\\\; \\\\obsdata^{\\\\mytableoned} \\\\right)$\":\n",
    "#         ignore_index.add(i)\n",
    "\n",
    "# for i,v in enumerate(data['label']):\n",
    "#     if all([v != sv for sv in all_sweep_vals]):\n",
    "#         print(data['label'][i])\n",
    "#         ignore_index.add(i)\n",
    "\n",
    "# ignore_index = list(ignore_index)\n",
    "# data_slice = deepcopy(data)\n",
    "# IGNORED_COLUMNS = ['outputs','x_group','y_group','z_group','annotate','hatch','x_id','y_id','z_id']\n",
    "\n",
    "# for k in data_slice.keys():\n",
    "#     if k not in IGNORED_COLUMNS:\n",
    "#         data_slice[k] = [data_slice[k][j] for j in range(len(data_slice[k])) if j not in ignore_index]\n",
    "\n",
    "# for k,v in data_slice.items():\n",
    "#     if len(np.shape(v)) > 0 and np.shape(v)[0] > 0:\n",
    "#         print(k,np.shape(v))\n",
    "\n",
    "# write_json(\n",
    "#     data = data_slice,\n",
    "#     filepath = \"../../data/outputs/cambridge/exp3/paper_figures/figure4_rerun_v2/loss_function_validation_all_odms_data.json\"\n",
    "# )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "50c4c16e",
   "metadata": {},
   "source": [
    "# Run output summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "80b2e092",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Specify experiment id\n",
    "experiment_id = \"JointTableSIM_NN_SweepedNoise_01_02_2024_14_55_23\"\n",
    "# Specify experiment group id\n",
    "experiment_group_id = 'exp3/'\n",
    "dataset = 'cambridge'\n",
    "experiment_dir = f'../../data/outputs/{dataset}/{experiment_group_id}/{experiment_id}/'\n",
    "relative_experiment_dir = os.path.relpath(experiment_dir,os.getcwd())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bba0f2ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Output processing settings\n",
    "settings = {\n",
    "    \"logging_mode\": \"INFO\",\n",
    "    \"out_group\":\"exp3\",\n",
    "    \"experiment_type\":\"JointTableSIM_NN\",\n",
    "    \"dataset_name\":[\"cambridge\"],\n",
    "    \"out_directory\":\"../../data/outputs/\",\n",
    "    \"coordinate_slice\": [\n",
    "        \"~da.title.isin(['_unconstrained','_total_intensity_row_table_constrained'])\",\n",
    "        \"~da.loss_name.isin(['[total_intensity_distance_loss]','[total_table_distance_loss]','[dest_attraction_ts_likelihood_loss,table_likelihood_loss]'])\"\n",
    "    ],\n",
    "    \"burnin_thinning_trimming\": [],\n",
    "    \"evaluation_library\":[\"np\",\"MathUtils\",\"xr\"],\n",
    "    \"evaluate\": [\n",
    "        (\"table_coverage_probability_size\",\"coverage_probability(prediction=table,ground_truth=ground_truth,dim='iter').mean(['origin','destination'])\"),\n",
    "        (\"table_srmse\",\"srmse(prediction=table.mean('iter'),ground_truth=ground_truth)\")\n",
    "    ],\n",
    "    \"evaluation_kwargs\": [\n",
    "        (\"table\", ''),\n",
    "        (\"ground_truth\",\"outputs.inputs.data.ground_truth_table\"),\n",
    "        (\"srmse\",\"MathUtils.srmse\"),\n",
    "        (\"coverage_probability\",\"MathUtils.coverage_probability\")\n",
    "    ],\n",
    "    \"metadata_keys\":[\"sigma\",\"type\",\"title\",\"loss_name\"],\n",
    "    \"sample\":[\"table\"],\n",
    "    \"group_by\":[],\n",
    "    \"filename_ending\":\"test\",\n",
    "    \"slice\":False,\n",
    "    \"force_reload\":False,\n",
    "    \"n_workers\": 1\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a9b0b39",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create new logging object\n",
    "logger = setup_logger(\n",
    "    __name__,\n",
    "    console_level = 'INFO',\n",
    "    file_level = 'EMPTY'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d5722d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run output handler\n",
    "outsum = OutputSummary(\n",
    "    settings = settings,\n",
    "    logger = logger\n",
    ")\n",
    "# Collect\n",
    "experiment_metadata = outsum.collect_metadata()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "gensit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

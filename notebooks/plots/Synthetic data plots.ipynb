{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from tqdm import tqdm\n",
    "from functools import partial\n",
    "from gensit.utils.misc_utils import *\n",
    "\n",
    "from gensit.static.plot_variables import *\n",
    "from gensit.static.global_variables import *\n",
    "\n",
    "\n",
    "# LaTeX font configuration\n",
    "mpl.rcParams.update(LATEX_RC_PARAMETERS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "\n",
    "# AUTO RELOAD EXTERNAL MODULES\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "node_gt_pairs = [\n",
    "    (50,1_000_000),\n",
    "    (100,1_000_000),\n",
    "    (150,1_000_000),\n",
    "    (200,1_000_000),\n",
    "    (250,10_000),\n",
    "    (250,100_000),\n",
    "    (250,250_000),\n",
    "    (250,500_000),\n",
    "    (250,1_000_000)\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for node,total in tqdm(node_gt_pairs):\n",
    "#     dataset = f\"synthetic_{node}x{node}_total_{total}\"\n",
    "#     ground_truth_table = np.loadtxt(f'../data/inputs/synthetic/{dataset}/ground_truth_table.txt')\n",
    "#     I,J = np.shape(ground_truth_table)\n",
    "#     training_cells = np.array([ [i,j] for i in range(I) for j in range(0,J//2)], dtype=np.int32)\n",
    "#     test_cells = np.array([ [i,j] for i in range(I) for j in range(J//2,J)], dtype=np.int32)\n",
    "#     os.mkdir(f\"../data/inputs/synthetic/{dataset}/constraints/\")\n",
    "#     np.savetxt(f\"../data/inputs/synthetic/{dataset}/constraints/training_cells_50%.txt\",training_cells)\n",
    "#     np.savetxt(f\"../data/inputs/synthetic/{dataset}/constraints/test_cells_50%.txt\",test_cells)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# nodes = 500\n",
    "# total = 250_000\n",
    "\n",
    "\n",
    "# dataset = f\"synthetic_{nodes}x{nodes}_total_{total}\"\n",
    "# ground_truth_table = np.loadtxt(f'../data/inputs/synthetic/{dataset}/ground_truth_table.txt')\n",
    "# cost_matrix = np.loadtxt(f'../data/inputs/synthetic/{dataset}/cost_matrix.txt')\n",
    "# I,J = np.shape(ground_truth_table)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Computation time figure"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "total_compute = read_json(\"../data/outputs/synthetic/paper_figures/figure0/gensit_total_compute_times_n1000_label_type_markersize_1.0_linewidth_1.0_opacity_1.0_hatchopacity_1.0_data.json\")\n",
    "table_compute = read_json(\"../data/outputs/synthetic/paper_figures/figure0/gensit_table_compute_times_n1000_label_type_markersize_1.0_linewidth_1.0_opacity_1.0_hatchopacity_1.0_data.json\")\n",
    "intensity_compute = read_json(\"../data/outputs/synthetic/paper_figures/figure0/gensit_intensity_compute_times_n1000_label_type_markersize_1.0_linewidth_1.0_opacity_1.0_hatchopacity_1.0_data.json\")\n",
    "\n",
    "total_compute = {\n",
    "    \"x\": np.array(list(flatten(total_compute['x']))),\n",
    "    \"origins\": np.array([int(x.split('x')[0]) for x in list(flatten(np.array(total_compute['x'])))]),\n",
    "    \"destinations\": np.array([int(x.split('x')[1]) for x in list(flatten(np.array(total_compute['x'])))]),\n",
    "    \"origins_x_destinations\": np.array([int(x.split('x')[0])*int(x.split('x')[1]) for x in list(flatten(np.array(total_compute['x'])))]),\n",
    "    \"y\": np.array(list(flatten(total_compute['y']))),\n",
    "    \"label\": np.array(total_compute['label']),\n",
    "    \"order\": np.argsort([int(x.split('x')[0]) for x in list(flatten(np.array(total_compute['x'])))])\n",
    "}\n",
    "table_compute = {\n",
    "    \"x\": np.array(list(flatten(table_compute['x']))),\n",
    "    \"y\": np.array(list(flatten(table_compute['y']))),\n",
    "    \"origins\": np.array([int(x.split('x')[0]) for x in list(flatten(np.array(table_compute['x'])))]),\n",
    "    \"destinations\": np.array([int(x.split('x')[1]) for x in list(flatten(np.array(table_compute['x'])))]),\n",
    "    \"origins_x_destinations\": np.array([int(x.split('x')[0])*int(x.split('x')[1]) for x in list(flatten(np.array(table_compute['x'])))]),\n",
    "    \"label\": np.array(table_compute['label']),\n",
    "    \"order\": np.argsort([int(x.split('x')[0]) for x in list(flatten(np.array(table_compute['x'])))])\n",
    "}\n",
    "intensity_compute = {\n",
    "    \"x\": np.array(list(flatten(intensity_compute['x']))),\n",
    "    \"y\": np.array(list(flatten(intensity_compute['y']))),\n",
    "    \"origins\": np.array([int(x.split('x')[0]) for x in list(flatten(np.array(intensity_compute['x'])))]),\n",
    "    \"destinations\": np.array([int(x.split('x')[1]) for x in list(flatten(np.array(intensity_compute['x'])))]),\n",
    "    \"origins_x_destinations\": np.array([int(x.split('x')[0])*int(x.split('x')[1]) for x in list(flatten(np.array(intensity_compute['x'])))]),\n",
    "    \"label\": np.array(intensity_compute['label']),\n",
    "    \"order\": np.argsort([int(x.split('x')[0]) for x in list(flatten(np.array(intensity_compute['x'])))])\n",
    "}\n",
    "\n",
    "# Re-order \n",
    "total_compute['x'] = np.array(total_compute['x'][total_compute['order']])\n",
    "total_compute['y'] = np.array(total_compute['y'][total_compute['order']])\n",
    "total_compute['origins'] = np.array(total_compute['origins'][total_compute['order']])\n",
    "total_compute['destinations'] = np.array(total_compute['destinations'][total_compute['order']])\n",
    "total_compute['origins_x_destinations'] = np.array(total_compute['origins_x_destinations'][total_compute['order']])\n",
    "total_compute['label'] = np.array(total_compute['label'][total_compute['order']])\n",
    "\n",
    "table_compute['x'] = np.array(table_compute['x'][table_compute['order']])\n",
    "table_compute['y'] = np.array(table_compute['y'][table_compute['order']])\n",
    "table_compute['origins'] = np.array(table_compute['origins'][table_compute['order']])\n",
    "table_compute['destinations'] = np.array(table_compute['destinations'][table_compute['order']])\n",
    "table_compute['origins_x_destinations'] = np.array(table_compute['origins_x_destinations'][table_compute['order']])\n",
    "table_compute['label'] = np.array(table_compute['label'][table_compute['order']])\n",
    "\n",
    "intensity_compute['x'] = np.array(intensity_compute['x'][intensity_compute['order']])\n",
    "intensity_compute['y'] = np.array(intensity_compute['y'][intensity_compute['order']])\n",
    "intensity_compute['origins'] = np.array(intensity_compute['origins'][intensity_compute['order']])\n",
    "intensity_compute['destinations'] = np.array(intensity_compute['destinations'][intensity_compute['order']])\n",
    "intensity_compute['origins_x_destinations'] = np.array(intensity_compute['origins_x_destinations'][intensity_compute['order']])\n",
    "intensity_compute['label'] = np.array(intensity_compute['label'][intensity_compute['order']])\n",
    "\n",
    "# Transform\n",
    "# transformation = partial(np.emath.logn,4)\n",
    "transformation = lambda x: x\n",
    "total_compute['y'] = np.array(transformation(total_compute['y']))\n",
    "total_compute['origins_x_destinations'] = np.array(transformation(total_compute['origins_x_destinations']))\n",
    "table_compute['y'] = np.array(transformation(table_compute['y']))\n",
    "table_compute['origins_x_destinations'] = np.array(transformation(table_compute['origins_x_destinations']))\n",
    "intensity_compute['y'] = np.array(transformation(intensity_compute['y']))\n",
    "intensity_compute['origins_x_destinations'] = np.array(transformation(intensity_compute['origins_x_destinations']))\n",
    "\n",
    "\n",
    "# Color\n",
    "colours = {\n",
    "    '\\\\frameworktag (Disjoint)': \"blue\",\n",
    "    '\\\\frameworktag (Joint)': \"green\",\n",
    "    '\\\\gaskinframeworktag': \"red\"\n",
    "}\n",
    "total_compute['colour'] = [colours[l] for l in total_compute['label']]\n",
    "table_compute['colour'] = [colours[l] for l in table_compute['label']]\n",
    "intensity_compute['colour'] = [colours[l] for l in intensity_compute['label']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "total_compute['x']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "LABEL_SIZE = 25\n",
    "LEGEND_SIZE = 18\n",
    "TICK_PAD = 0\n",
    "TICK_SIZE = 25\n",
    "TICK_ROTATION = 0\n",
    "Y_LABELS = ['Total Compute Time (s)','Table Sampling Time (s)','Intensity Learning Time (s)']\n",
    "filepath = \"../data/outputs/synthetic/paper_figures/figure0/gensit_computation_time_scalability_with_dimension\"\n",
    "\n",
    "X_VAR = 'origins_x_destinations'\n",
    "Y_VAR = 'y'\n",
    "\n",
    "# Index of method (label)\n",
    "index = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axs = plt.subplots(1,3,figsize=(20,5))\n",
    "\n",
    "### Table compute time\n",
    "for i in range(len(table_compute['x'])):\n",
    "    axs[1].scatter(\n",
    "        x = table_compute['origins_x_destinations'][i],\n",
    "        y = table_compute['y'][i],\n",
    "        label = table_compute['label'][i],\n",
    "        c = table_compute['colour'][i],\n",
    "        marker = 's'\n",
    "    )\n",
    "for label in np.unique(table_compute['label']):\n",
    "    indices = np.argwhere(table_compute['label'] == label).T[0]\n",
    "    axs[1].plot(\n",
    "        table_compute['origins_x_destinations'][indices],\n",
    "        table_compute['y'][indices],\n",
    "        color = table_compute['colour'][indices[0]]\n",
    "    )\n",
    "first_time = 2.7\n",
    "table_coeff = 0.002\n",
    "table_complexities = [ table_compute['origins'][m]*table_compute['destinations'][m] for m in list(range(index,len(table_compute['x']),2))]\n",
    "table_factors = [1.0 if fi == 0 else table_complexities[fi]/table_complexities[fi-1] for fi in range(len(table_complexities))]\n",
    "table_theoretical_time = transformation([first_time*(1 + int(fi>0)*table_coeff*np.prod(table_factors[:(fi+1)])) for fi in range(len(table_factors))])\n",
    "# table_theoretical_time = transformation([3]*len(table_factors))\n",
    "axs[1].plot(\n",
    "    table_compute['origins_x_destinations'][indices],\n",
    "    table_theoretical_time,\n",
    "    color = 'black',\n",
    "    label = r'$\\bigoh{NEIJ}$'\n",
    ")\n",
    "\n",
    "### Intensity compute time\n",
    "for i in range(len(intensity_compute['x'])):\n",
    "    axs[2].scatter(\n",
    "        x = intensity_compute['origins_x_destinations'][i],\n",
    "        y = intensity_compute['y'][i],\n",
    "        label = intensity_compute['label'][i],\n",
    "        c = intensity_compute['colour'][i],\n",
    "        marker = '^'\n",
    "    )\n",
    "for label in np.unique(intensity_compute['label']):\n",
    "    indices = np.argwhere(intensity_compute['label'] == label).T[0]\n",
    "    axs[2].plot(\n",
    "        intensity_compute['origins_x_destinations'][indices],\n",
    "        intensity_compute['y'][indices],\n",
    "        color = intensity_compute['colour'][indices[0]]\n",
    "    )\n",
    "first_time = intensity_compute['y'][index+1] + 1\n",
    "intensity_coeff = 0.013\n",
    "intensity_complexities = [ intensity_compute['destinations'][m]*(intensity_compute['origins'][m]) for m in list(range(index,len(intensity_compute['x']),2))]\n",
    "intensity_factors = [1.0 if fi == 0 else intensity_complexities[fi]/intensity_complexities[fi-1] for fi in range(len(intensity_complexities))]\n",
    "intensity_theoretical_time = transformation([first_time*(1 + int(fi>0)*intensity_coeff*np.prod(intensity_factors[:(fi+1)])) for fi in range(len(intensity_factors))])\n",
    "axs[2].plot(\n",
    "    intensity_compute['origins_x_destinations'][indices],\n",
    "    intensity_theoretical_time,\n",
    "    color = 'black',\n",
    "    label = r'$\\bigoh{NE(\\tau J+IJ)}$'\n",
    ")\n",
    "\n",
    "### Total compute time\n",
    "for i in range(len(total_compute['x'])):\n",
    "    axs[0].scatter(\n",
    "        x = total_compute['origins_x_destinations'][i],\n",
    "        y = total_compute['y'][i],\n",
    "        label = total_compute['label'][i],\n",
    "        c = total_compute['colour'][i],\n",
    "        marker = 'o'\n",
    "    )\n",
    "for label in np.unique(total_compute['label']):\n",
    "    indices = np.argwhere(total_compute['label'] == label).T[0]\n",
    "    axs[0].plot(\n",
    "        total_compute['origins_x_destinations'][indices],\n",
    "        total_compute['y'][indices],\n",
    "        color = total_compute['colour'][indices[0]]\n",
    "    )\n",
    "axs[0].plot(\n",
    "    total_compute['origins_x_destinations'][indices],\n",
    "    np.array(intensity_theoretical_time)+np.array(table_theoretical_time),\n",
    "    color = 'black',\n",
    "    label = r'$\\bigoh{NE(\\tau J+IJ)}$'\n",
    ")\n",
    "\n",
    "for j,ax in enumerate(axs):\n",
    "    # Create dictionary of labels\n",
    "    by_label = {}\n",
    "    handles, label, label_split = [],[],[]\n",
    "    # Ensure no duplicate entries in legend exist\n",
    "    ax_handles, ax_labels = ax.get_legend_handles_labels()\n",
    "    # Convert everything to numpy arrays\n",
    "    ax_label_split = [lab.split(', ') for lab in ax_labels]\n",
    "\n",
    "    # Add legend handles and labels to list\n",
    "    handles += ax_handles\n",
    "    label_split += ax_label_split\n",
    "    label += ax_labels\n",
    "\n",
    "    label_split = np.array(label_split,dtype='str')\n",
    "    # Sort label first by first label, then by second etc.\n",
    "    index_sorted = np.lexsort(label_split.T)\n",
    "    # Do not worry about duplicates. These will be handled here\n",
    "    # Create dictionary of label\n",
    "    by_label = dict(zip(\n",
    "        np.array(label)[index_sorted].tolist(), \n",
    "        np.array(handles)[index_sorted].tolist()\n",
    "    ))\n",
    "\n",
    "    # If more than one column are provided split legend patches and keys\n",
    "    # into sublists of length ncols\n",
    "    leg = ax.legend(\n",
    "        flip(list(by_label.values()), 1), \n",
    "        flip(list(by_label.keys()), 1),\n",
    "        frameon = False,\n",
    "        prop = {'size':LEGEND_SIZE},\n",
    "    )\n",
    "    leg._ncol = 1\n",
    "\n",
    "    ax.set_ylabel(Y_LABELS[j],fontsize=LABEL_SIZE)\n",
    "    ax.set_xlabel('$IJ$',fontsize=LABEL_SIZE)\n",
    "    ax.tick_params(\n",
    "        pad = TICK_PAD,\n",
    "        bottom = True,\n",
    "        labelsize = TICK_SIZE,\n",
    "        rotation = TICK_ROTATION\n",
    "    )\n",
    "    ax.xaxis.offsetText.set_fontsize(TICK_SIZE)\n",
    "\n",
    "# fig.tight_layout(rect=(0, 0, 0.7, 1.1))\n",
    "fig.tight_layout(rect=(0, 0, 1, 1))\n",
    "plt.show()\n",
    "# Write figure\n",
    "write_figure(\n",
    "    fig,\n",
    "    filepath,\n",
    "    figure_format = 'pdf'\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SRMSE with dimension plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dim_scalability = read_json(\"../data/outputs/synthetic/paper_figures/figure1/table_mcmc_dimension_scalability_direct_sampling_label_type_markersize_1.0_linewidth_1.0_opacity_1.0_hatchopacity_1.0_data.json\")\n",
    "\n",
    "dim_scalability = {\n",
    "    \"x\": np.array(list(flatten(dim_scalability['x']))),\n",
    "    \"origins\": np.array([int(x.split('x')[0]) for x in list(flatten(np.array(dim_scalability['x'])))]),\n",
    "    \"destinations\": np.array([int(x.split('x')[1]) for x in list(flatten(np.array(dim_scalability['x'])))]),\n",
    "    \"y\": np.array(list(flatten(dim_scalability['y']))),\n",
    "    \"label\": np.array(dim_scalability['label']),\n",
    "    \"order\": np.argsort([int(x.split('x')[0]) for x in list(flatten(np.array(dim_scalability['x'])))])\n",
    "}\n",
    "\n",
    "# Re-order \n",
    "dim_scalability['x'] = list(dim_scalability['x'][dim_scalability['order']])\n",
    "dim_scalability['y'] = list(dim_scalability['y'][dim_scalability['order']])\n",
    "dim_scalability['origins'] = list(dim_scalability['origins'][dim_scalability['order']])\n",
    "dim_scalability['destinations'] = list(dim_scalability['destinations'][dim_scalability['order']])\n",
    "dim_scalability['label'] = list(dim_scalability['label'][dim_scalability['order']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "LABEL_SIZE = 25\n",
    "LEGEND_SIZE = 20\n",
    "TICK_PAD = 0\n",
    "TICK_SIZE = 20\n",
    "TICK_ROTATION = 0\n",
    "Y_LABEL = r'SRMSE$(\\mathbb{E}[\\mytable^{(1:N)}\\vert\\myintensity],\\groundtruthtable)$'\n",
    "dim_scalability_filepath = \"../data/outputs/synthetic/paper_figures/figure1/table_mcmc_srmse_scalability_with_dimension_direct_sampling\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(1,1,figsize=(7,5))\n",
    "\n",
    "### SRMSE vs dimensions\n",
    "for i in range(len(dim_scalability['x'])):\n",
    "    ax.plot(\n",
    "        dim_scalability['x'],\n",
    "        dim_scalability['y'],\n",
    "        label = dim_scalability['label'],\n",
    "        marker = 'o',\n",
    "        color = 'blue'\n",
    "    )\n",
    "\n",
    "ax.set_ylabel(Y_LABEL,fontsize=LABEL_SIZE)\n",
    "ax.set_xlabel('ODM Dimension',fontsize=LABEL_SIZE)\n",
    "ax.tick_params(\n",
    "    pad = TICK_PAD,\n",
    "    bottom = True,\n",
    "    labelsize = TICK_SIZE,\n",
    "    rotation = TICK_ROTATION\n",
    ")\n",
    "\n",
    "# fig.tight_layout(rect=(0, 0, 0.7, 1.1))\n",
    "fig.tight_layout(rect=(0, 0, 1, 1))\n",
    "plt.show()\n",
    "# Write figure\n",
    "write_figure(\n",
    "    fig,\n",
    "    dim_scalability_filepath,\n",
    "    figure_format = 'pdf'\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SRMSE with total number of agents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "agent_scalability = read_json(\"../data/outputs/synthetic/paper_figures/figure2/table_mcmc_agent_scalability_direct_sampling_label_proposal_markersize_1.0_linewidth_1.0_opacity_1.0_hatchopacity_1.0_data.json\")\n",
    "\n",
    "agent_scalability = {\n",
    "    \"x\": np.array(list(flatten(agent_scalability['x']))),\n",
    "    \"y\": np.array(list(flatten(agent_scalability['y']))),\n",
    "    \"label\": np.array(list(flatten(agent_scalability['label']))),\n",
    "    \"order\": np.argsort([x for x in list(flatten(np.array(agent_scalability['x'])))])\n",
    "}\n",
    "\n",
    "# Re-order \n",
    "agent_scalability['x'] = list(agent_scalability['x'][agent_scalability['order']])\n",
    "agent_scalability['y'] = list(agent_scalability['y'][agent_scalability['order']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "LABEL_SIZE = 25\n",
    "LEGEND_SIZE = 20\n",
    "TICK_PAD = 0\n",
    "TICK_SIZE = 20\n",
    "TICK_ROTATION = 0\n",
    "Y_LABEL = r'$\\text{SRMSE}(\\mathbb{E}[\\mytable^{(1:N)}\\vert\\myintensity],\\groundtruthtable)$'\n",
    "agent_scalability_filepath = \"../data/outputs/synthetic/paper_figures/figure2/table_mcmc_srmse_scalability_with_agent_number_direct_sampling\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(1,1,figsize=(7,5))\n",
    "\n",
    "### SRMSE vs dimensions\n",
    "for i in range(len(agent_scalability['x'])):\n",
    "    ax.plot(\n",
    "        agent_scalability['x'],\n",
    "        agent_scalability['y'],\n",
    "        label = agent_scalability['label'],\n",
    "        marker = 'o',\n",
    "        color = 'blue'\n",
    "    )\n",
    "\n",
    "ax.set_ylabel(Y_LABEL,fontsize=LABEL_SIZE)\n",
    "ax.set_xlabel('Number of Agents $A$',fontsize=LABEL_SIZE)\n",
    "ax.tick_params(\n",
    "    pad = TICK_PAD,\n",
    "    bottom = True,\n",
    "    labelsize = TICK_SIZE,\n",
    "    rotation = TICK_ROTATION\n",
    ")\n",
    "ax.set_xticks(agent_scalability['x'])\n",
    "ax.xaxis.offsetText.set_fontsize(TICK_SIZE)\n",
    "\n",
    "# fig.tight_layout(rect=(0, 0, 0.7, 1.1))\n",
    "fig.tight_layout(rect=(0, 0, 1, 1))\n",
    "plt.show()\n",
    "# Write figure\n",
    "write_figure(\n",
    "    fig,\n",
    "    agent_scalability_filepath,\n",
    "    figure_format = 'pdf'\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "gensit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

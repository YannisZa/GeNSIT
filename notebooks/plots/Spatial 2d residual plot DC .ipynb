{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c76b8620",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import glob\n",
    "import warnings\n",
    "import h5py as h5\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib as mpl\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.colors as mcolors\n",
    "\n",
    "from itertools import product\n",
    "from tqdm.auto import tqdm\n",
    "from copy import deepcopy\n",
    "\n",
    "from gensit.config import Config\n",
    "from gensit.inputs import Inputs\n",
    "from gensit.outputs import Outputs\n",
    "from gensit.utils.misc_utils import *\n",
    "from gensit.utils.math_utils import *\n",
    "from gensit.utils.probability_utils import *\n",
    "from gensit.contingency_table import instantiate_ct\n",
    "from gensit.contingency_table.MarkovBasis import instantiate_markov_basis\n",
    "from gensit.static.plot_variables import LATEX_RC_PARAMETERS, COLOR_NAMES\n",
    "from gensit.contingency_table.ContingencyTable_MCMC import ContingencyTableMarkovChainMonteCarlo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b718b815",
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "\n",
    "# AUTO RELOAD EXTERNAL MODULES\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d610efec",
   "metadata": {},
   "outputs": [],
   "source": [
    "# LaTeX font configuration\n",
    "mpl.rcParams.update(LATEX_RC_PARAMETERS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "188d0194",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create new logging object\n",
    "logger = setup_logger(\n",
    "    __name__,\n",
    "    console_level = 'INFO',\n",
    "    file_level = 'EMPTY'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "494e6140",
   "metadata": {},
   "outputs": [],
   "source": [
    "config = Config(\n",
    "    \"../../data/inputs/configs/DC/vanilla_comparisons.toml\"\n",
    ")\n",
    "inputs = Inputs(\n",
    "    config = config,\n",
    "    synthetic_data = False,\n",
    "    logger = logger\n",
    ")\n",
    "inputs.cast_to_xarray()\n",
    "ground_truth_table = inputs.data.ground_truth_table"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0ded5de8",
   "metadata": {},
   "source": [
    "# Metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f5c9acd",
   "metadata": {},
   "outputs": [],
   "source": [
    "lines = []\n",
    "for experiment_id in [\n",
    "    \"JointTableSIM_NN_SweepedNoise__doubly_and_cell_constrained_ensemble5_neighbourhood_cell_split_03_06_2025_14_42_51\",\n",
    "    \"NonJointTableSIM_NN_SweepedNoise__doubly_and_cell_constrained_ensemble5_neighbourhood_cell_split_03_06_2025_14_43_10\",\n",
    "]:\n",
    "\n",
    "    method_name = \"disjoint_gensit\" if \"NonJointTableSIM\" in experiment_id else \"joint_gensit\"\n",
    "    sample_names = [\"intensity\"]#[\"table\",\"intensity\"]\n",
    "    sigmas = [0.1414213562, 0.0141421356, None]\n",
    "    sample_sigma_combinations = list(product(sample_names, sigmas))\n",
    "\n",
    "\n",
    "    method_out_path = f'../../data/outputs/DC/exp1/{experiment_id}/stored_results/'\n",
    "    makedir(method_out_path)\n",
    "    lines += [experiment_id]\n",
    "    print(experiment_id,'\\n')\n",
    "    for sample,sigma in tqdm(sample_sigma_combinations,total=len(sample_sigma_combinations),desc='Computing metrics over sigmas and samples'):\n",
    "        sigma_str = str(np.round(sigma,5) if sigma is not None else None)\n",
    "        settings = {\n",
    "            \"logging_mode\": \"INFO\",\n",
    "            \"coordinate_slice\": [],\n",
    "            \"slice\":False,\n",
    "            \"metadata_keys\":[],\n",
    "            \"burnin_thinning_trimming\": [],#{'iter': {\"burnin\":10000, \"thinning\":1, \"trimming\":100000}}\n",
    "            \"sample\":[sample],\n",
    "            \"group_by\":[],\n",
    "            \"filename_ending\":\"test\",\n",
    "            \"force_reload\":False,\n",
    "            \"n_workers\": 1\n",
    "            }\n",
    "        # Initialise outputs\n",
    "        method_outputs = Outputs(\n",
    "            config = f'../../data/outputs/DC/exp1/{experiment_id}/config.json',\n",
    "            settings = settings,\n",
    "            inputs = None,\n",
    "            slice = True,\n",
    "            level = 'ERROR'\n",
    "        )\n",
    "        # Silence outputs\n",
    "        method_outputs.logger.setLevels(console_level='ERROR')\n",
    "\n",
    "        n_iter = method_outputs.config.get('N',None)\n",
    "        all_seeds = method_outputs.config.get('seed',None)[:5]\n",
    "        n_ensemble = len(all_seeds)\n",
    "        print(f\"{sample} E={n_ensemble}, N={n_iter}, sigma={sigma_str}\")\n",
    "        sweep_configs = deepcopy(method_outputs.config.sweep_configurations)\n",
    "        print('Example sweep config',sweep_configs[0])\n",
    "\n",
    "        method_srmses, method_ssis, method_cps = [],[],[]\n",
    "        for seed in tqdm(all_seeds,total=len(all_seeds),desc='Computing metrics over seeds'):\n",
    "            print(f\"Seed {seed}\")\n",
    "            # Get sweep outputs\n",
    "            method_outputs_copy = deepcopy(method_outputs)\n",
    "            method_outputs_seed = method_outputs.get_sweep_outputs(\n",
    "                base_config = method_outputs.config,\n",
    "                # sweep_configuration=(seed, sigma, ['alpha', 'beta'], ['table_likelihood_loss'], ['custom'], {'nokey': None}),\n",
    "                sweep_configuration = (seed,sigma,['alpha', 'beta']),\n",
    "                sample_names = ['alpha','beta','log_destination_attraction'] if sample == 'intensity' else ['table'],\n",
    "                group_by = [],\n",
    "                index = 0\n",
    "            )\n",
    "            for sample_name,sample_data in method_outputs_seed.items():\n",
    "                setattr(\n",
    "                    method_outputs_copy.data,\n",
    "                    sample_name,\n",
    "                    [sample_data]\n",
    "                )\n",
    "            method_outputs_copy.stack_sweep_dims(method_outputs_copy)\n",
    "            method_outputs_copy = method_outputs_copy.get(0)\n",
    "            \n",
    "            if sample == \"intensity\":\n",
    "                method_sample = method_outputs_copy.get_sample('intensity')\n",
    "                for d in ['sigma','seed','to_learn']:\n",
    "                    if d in method_sample.dims:\n",
    "                        method_sample = method_sample.squeeze(d)\n",
    "            else:\n",
    "                method_sample = method_outputs_copy.data.table\n",
    "                for d in ['sigma','seed','to_learn']:\n",
    "                    if d in method_sample.dims:\n",
    "                        method_sample = method_sample.squeeze(d)\n",
    "            \n",
    "            method_srmse = srmse(\n",
    "                prediction = method_sample.mean(['iter'],dtype='float64'),\n",
    "                ground_truth = inputs.data.ground_truth_table,\n",
    "                mask = inputs.data.test_cells_mask\n",
    "            ).values\n",
    "            method_srmses.append(method_srmse)\n",
    "            method_ssi = ssi(\n",
    "                prediction = method_sample.mean(['iter'],dtype='float64'),\n",
    "                ground_truth = inputs.data.ground_truth_table,\n",
    "                mask = inputs.data.test_cells_mask\n",
    "            ).values\n",
    "            method_ssis.append(method_ssi)\n",
    "            method_cp = coverage_probability(\n",
    "                prediction = method_sample,\n",
    "                ground_truth = inputs.data.ground_truth_table,\n",
    "                dim = 'iter',\n",
    "                mask = inputs.data.test_cells_mask\n",
    "            ).mean(['origin','destination'],skipna=True).values\n",
    "            method_cps.append(method_cp)\n",
    "            # print(f\"SRMSE: {method_srmse}\")\n",
    "            # print(f\"SSI: {method_ssi}\")\n",
    "            # print(f\"CP: {method_cp}\")\n",
    "            # break\n",
    "\n",
    "        lines += [\n",
    "            f\"{sample} E={n_ensemble}, N={n_iter}, sigma={sigma_str} ==============\",\n",
    "            f\"SRMSE: mean={np.mean(method_srmses)}, std={np.std(method_srmses)}\",\n",
    "            f\"SSI: mean={np.mean(method_ssis)}, std={np.std(method_ssis)}\",\n",
    "            f\"CP: mean={np.mean(method_cps)}, std={np.std(method_cps)}\",\n",
    "            f\"========================================================\"\n",
    "        ]\n",
    "        \n",
    "        with open('../../data/outputs/DC/exp1/summaries/experiments_doubly_cell_constrained_SRMSEs_SSIs_CPs.txt', mode='w', buffering=1, encoding='utf-8') as f:  # Line buffered\n",
    "            for idx, line in enumerate(lines):\n",
    "                f.write(line if line.endswith('\\n') else line + '\\n')\n",
    "                f.flush()  # Ensure it's written\n",
    "                os.fsync(f.fileno())\n",
    "\n",
    "        # break\n",
    "    # break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "74d15360",
   "metadata": {},
   "outputs": [],
   "source": [
    "ct_config = Config(\n",
    "    \"../../data/inputs/configs/DC/experiment1_nn_joint.toml\"\n",
    ")\n",
    "ct_inputs = Inputs(\n",
    "    config = ct_config,\n",
    "    synthetic_data = False,\n",
    "    logger = logger\n",
    ")\n",
    "del ct_inputs.true_parameters\n",
    "ct_inputs.pass_to_device()\n",
    "ct_inputs.cast_to_xarray(datasets = [\n",
    "    'train_cells_mask',\n",
    "    'test_cells_mask',\n",
    "    'validation_cells_mask'\n",
    "])\n",
    "ct = instantiate_ct(\n",
    "    config = ct_config,\n",
    "    logger = logger,\n",
    "    **vars(ct_inputs.data)\n",
    ")\n",
    "# ct_mcmc = ContingencyTableMarkovChainMonteCarlo(\n",
    "#     ct = ct,\n",
    "#     log_to_console = False,\n",
    "#     logger = logger\n",
    "# )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e8afcfb5",
   "metadata": {},
   "outputs": [],
   "source": [
    "samples = torch.tensor(method_sample.squeeze('sweep').values,dtype=torch.int32)\n",
    "for s in tqdm(samples[::100]):\n",
    "    assert ct.table_admissible(s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d2ff4351",
   "metadata": {},
   "outputs": [],
   "source": [
    "n_cells_changed = 0\n",
    "for c in tqdm(inputs.data.test_cells):\n",
    "    unique_vals = torch.unique(samples[:,c[0],c[1]])\n",
    "    n_cells_changed += int((len(unique_vals) > 1) or (unique_vals[0]>0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e077a2a",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(n_cells_changed,'out of',len(inputs.data.test_cells),'(',int(100*n_cells_changed/len(inputs.data.test_cells)),'% )')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21833e02",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Apply mask to all samples: result will be (N, M) where M is number of True in mask\n",
    "masked_values = method_sample.squeeze('sweep').values#.where(inputs.data.test_cells_mask).values\n",
    "masked_values_flat = masked_values.reshape(masked_values.shape[0], -1)\n",
    "print(masked_values_flat.shape)\n",
    "# Compute absolute successive differences: abs(x[i+1] - x[i])\n",
    "diffs = np.abs(np.diff(masked_values_flat, axis=0)) \n",
    "# Sum the differences across axis 1 for each sample\n",
    "sum_diffs = diffs.max(axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "061c9481",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.count_nonzero(sum_diffs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "08db2ca7",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10,10))\n",
    "plt.plot(range(sum_diffs.shape[0]),sum_diffs)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "823801b3",
   "metadata": {},
   "source": [
    "# GeNSIT (Disjoint)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d46d4c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "sample = \"table\"\n",
    "reload = False\n",
    "\n",
    "n_iter = 100000\n",
    "n_ensemble = 10\n",
    "seeds = range(1,n_ensemble+1)\n",
    "sigma = 0.1414213562\n",
    "#0.1414213562, None, 0.0141421356\n",
    "\n",
    "# experiment_id = \"NonJointTableSIM_NN_SweepedNoise__totally_and_cell_constrained_20_05_2024_15_57_08\"\n",
    "experiment_id = \"NonJointTableSIM_NN_SweepedNoise__doubly_and_cell_constrained_29_05_2025_18_04_43_ensemble10\"\n",
    "disjointgensit_out_path = f'../../data/outputs/DC/exp1/{experiment_id}/stored_results/'\n",
    "makedir(disjointgensit_out_path)\n",
    "sigma_str = str(np.round(sigma,5) if sigma is not None else None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6112099b",
   "metadata": {},
   "outputs": [],
   "source": [
    "if sample == \"intensity\":\n",
    "    settings = {\n",
    "        \"logging_mode\": \"INFO\",\n",
    "        \"coordinate_slice\": [\n",
    "            f\"da.sigma=={sigma_str}\"\n",
    "        ],\n",
    "        \"slice\":True,\n",
    "        \"metadata_keys\":[],\n",
    "        \"burnin_thinning_trimming\": [],#{'iter': {\"burnin\":10000, \"thinning\":1, \"trimming\":100000}}\n",
    "        \"sample\":[sample],\n",
    "        \"group_by\":[],\n",
    "        \"filename_ending\":\"test\",\n",
    "        \"force_reload\":False,\n",
    "        \"n_workers\": 1\n",
    "    }\n",
    "        \n",
    "    disjointgensit_intensity_mean_path = os.path.join(disjointgensit_out_path,f'disjoint_gensit_{sample}_mean_E{n_ensemble}_N{n_iter}_sigma{sigma_str}.nc')\n",
    "    if (not os.path.exists(disjointgensit_intensity_mean_path) or reload):\n",
    "        # Initialise outputs\n",
    "        disjointgensit_outputs = Outputs(\n",
    "            config = f'../../data/outputs/DC/exp1/{experiment_id}/config.json',\n",
    "            settings = settings,\n",
    "            inputs = None,\n",
    "            slice = True,\n",
    "            level = 'ERROR'\n",
    "        )\n",
    "        # Silence outputs\n",
    "        disjointgensit_outputs.logger.setLevels(console_level='NOTE')\n",
    "        # Load all data\n",
    "        disjointgensit_outputs.load()\n",
    "\n",
    "        # Get data from first sweep of the experiment\n",
    "        disjointgensit_outputs = disjointgensit_outputs.get(0)\n",
    "\n",
    "        # Compute \n",
    "        disjointgensit_intensity_means = []\n",
    "        for s in tqdm(disjointgensit_outputs.data.alpha.coords['seed'].values):\n",
    "            disjointgensit_outputs_group = disjointgensit_outputs.select('seed',s)\n",
    "            disjointgensit_intensity_group = disjointgensit_outputs_group.get_sample('intensity')\n",
    "            disjointgensit_intensity_means.append(disjointgensit_intensity_group.mean(['iter'],dtype='float64'))\n",
    "        disjointgensit_intensity_mean = xr.concat(\n",
    "            disjointgensit_intensity_means, \n",
    "            dim='seed'\n",
    "        ).reset_index('sweep')\n",
    "        disjointgensit_intensity_mean.to_netcdf(path=disjointgensit_intensity_mean_path)\n",
    "    elif os.path.exists(disjointgensit_intensity_mean_path):\n",
    "        print('Loaded',disjointgensit_intensity_mean_path)\n",
    "        disjointgensit_intensity_mean = xr.open_dataarray(disjointgensit_intensity_mean_path)\n",
    "\n",
    "else:\n",
    "\n",
    "    settings = {\n",
    "        \"logging_mode\": \"INFO\",\n",
    "        \"coordinate_slice\": [],\n",
    "        \"slice\":False,\n",
    "        \"metadata_keys\":[],\n",
    "        \"burnin_thinning_trimming\": [],#{'iter': {\"burnin\":10000, \"thinning\":1, \"trimming\":100000}}\n",
    "        \"sample\":[sample],\n",
    "        \"group_by\":[],\n",
    "        \"filename_ending\":\"test\",\n",
    "        \"force_reload\":True,\n",
    "        \"n_workers\": 1\n",
    "    }\n",
    "    disjointgensit_table_mean_path = os.path.join(disjointgensit_out_path,f'disjoint_gensit_{sample}_mean_E{n_ensemble}_N{n_iter}_sigma{sigma_str}.nc')\n",
    "\n",
    "    if (not os.path.exists(disjointgensit_table_mean_path) or reload):\n",
    "        disjointgensit_table_means = []\n",
    "        for seed in tqdm(seeds):\n",
    "            # Initialise outputs\n",
    "            disjointgensit_outputs = Outputs(\n",
    "                config = f'../../data/outputs/DC/exp1/{experiment_id}/config.json',\n",
    "                settings = settings,\n",
    "                inputs = None,\n",
    "                slice = True,\n",
    "                level = 'ERROR'\n",
    "            )\n",
    "            # Silence outputs\n",
    "            disjointgensit_outputs.logger.setLevels(console_level='NOTE')\n",
    "            # Slice sweep configurations\n",
    "            print('BEFORE EDITTING',disjointgensit_outputs.config.sweep_configurations)\n",
    "            disjointgensit_outputs.config.sweep_configurations = [(seed, sigma, ['alpha', 'beta'])]\n",
    "            print('AFTER EDITTING',disjointgensit_outputs.config.sweep_configurations)\n",
    "            # Load all data\n",
    "            disjointgensit_outputs.load()\n",
    "\n",
    "            # Get data from first sweep of the experiment\n",
    "            disjointgensit_outputs = disjointgensit_outputs.get(0)\n",
    "            \n",
    "            # Compute mean and add it to list\n",
    "            disjointgensit_table_means.append(disjointgensit_outputs.data.table.mean(['iter'],dtype='float64'))\n",
    "\n",
    "        # Compute mean across seeds\n",
    "        disjointgensit_table_mean = xr.concat(\n",
    "            disjointgensit_table_means, \n",
    "            dim='seed'\n",
    "        ).reset_index('sweep')\n",
    "        disjointgensit_table_mean.to_netcdf(path=disjointgensit_table_mean_path)\n",
    "\n",
    "    elif os.path.exists(disjointgensit_table_mean_path):\n",
    "        print('Loaded',disjointgensit_table_mean_path)\n",
    "        disjointgensit_table_mean = xr.open_dataarray(disjointgensit_table_mean_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11f77d48",
   "metadata": {},
   "outputs": [],
   "source": [
    "if 'disjointgensit_table_mean' in globals():\n",
    "    disjointgensit_table_srmses = disjointgensit_table_mean.groupby('seed').map(\n",
    "        srmse,\n",
    "        ground_truth = inputs.data.ground_truth_table,\n",
    "        mask = inputs.data.test_cells_mask\n",
    "    ).values\n",
    "    print('disjointgensit_table_mean srmes',np.mean(disjointgensit_table_srmses),np.std(disjointgensit_table_srmses))\n",
    "if 'disjointgensit_intensity_mean' in globals():\n",
    "    disjointgensit_intensity_srmses = disjointgensit_intensity_mean.groupby('seed').map(\n",
    "        srmse,\n",
    "        ground_truth = inputs.data.ground_truth_table,\n",
    "        mask = inputs.data.test_cells_mask\n",
    "    ).values\n",
    "    print('disjointgensit_intensity_srmses srmes',np.mean(disjointgensit_intensity_srmses),np.std(disjointgensit_intensity_srmses))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "880cdfcb",
   "metadata": {},
   "source": [
    "# GeNSIT (Joint)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "477ed482",
   "metadata": {},
   "outputs": [],
   "source": [
    "sample = \"table\"\n",
    "reload = False\n",
    "\n",
    "n_iter = 100000\n",
    "n_ensemble = 5\n",
    "seeds = range(1,n_ensemble+1)\n",
    "# None,range(1,n_ensemble+1)\n",
    "sigma = 0.1414213562\n",
    "#0.1414213562, None, 0.0141421356\n",
    "\n",
    "experiment_id = 'JointTableSIM_NN_SweepedNoise__doubly_and_cell_constrained_29_05_2025_15_05_34_ensemble5'\n",
    "# experiment_id = 'JointTableSIM_NN_SweepedNoise__totally_and_cell_constrained_28_05_2025_19_41_33_ensemble5'\n",
    "jointgensit_out_path = f'../../data/outputs/DC/exp1/{experiment_id}/stored_results/'\n",
    "makedir(jointgensit_out_path)\n",
    "sigma_str = str(np.round(sigma,5) if sigma is not None else None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "833a9fad",
   "metadata": {},
   "outputs": [],
   "source": [
    "if sample == \"intensity\":\n",
    "    settings = {\n",
    "        \"logging_mode\": \"INFO\",\n",
    "        \"coordinate_slice\": [\n",
    "            f\"da.sigma=={sigma_str}\"\n",
    "        ],\n",
    "        \"slice\":True,\n",
    "        \"metadata_keys\":[],\n",
    "        \"burnin_thinning_trimming\": [],#{'iter': {\"burnin\":10000, \"thinning\":1, \"trimming\":100000}}\n",
    "        \"sample\":[sample],\n",
    "        \"group_by\":[],\n",
    "        \"filename_ending\":\"test\",\n",
    "        \"force_reload\":False,\n",
    "        \"n_workers\": 1\n",
    "    }\n",
    "\n",
    "    jointgensit_intensity_mean_path = os.path.join(jointgensit_out_path,f'joint_gensit_{sample}_mean_E{n_ensemble}_N{n_iter}_sigma{sigma_str}.nc')\n",
    "    if (not os.path.exists(jointgensit_intensity_mean_path) or reload):\n",
    "        # Initialise outputs\n",
    "        jointgensit_outputs = Outputs(\n",
    "            config = f'../../data/outputs/DC/exp1/{experiment_id}/config.json',\n",
    "            settings = settings,\n",
    "            inputs = None,\n",
    "            slice = True,\n",
    "            level = 'NOTE'\n",
    "        )\n",
    "        # Silence outputs\n",
    "        jointgensit_outputs.logger.setLevels(console_level='NOTE')\n",
    "        # Load all data\n",
    "        jointgensit_outputs.load()\n",
    "\n",
    "        # Get data from first sweep of the experiment\n",
    "        jointgensit_outputs = jointgensit_outputs.get(0)\n",
    "\n",
    "        # Compute \n",
    "        jointgensit_intensity_means = []\n",
    "        for s in tqdm(jointgensit_outputs.data.alpha.coords['seed'].values):\n",
    "            jointgensit_outputs_group = jointgensit_outputs.select('seed',s)\n",
    "            jointgensit_intensity_group = jointgensit_outputs_group.get_sample('intensity')\n",
    "            jointgensit_intensity_means.append(jointgensit_intensity_group.mean(['iter'],dtype='float64'))\n",
    "        jointgensit_intensity_mean = xr.concat(\n",
    "            jointgensit_intensity_means, \n",
    "            dim='seed'\n",
    "        ).reset_index('sweep')\n",
    "        jointgensit_intensity_mean.to_netcdf(path=jointgensit_intensity_mean_path)\n",
    "    elif os.path.exists(jointgensit_intensity_mean_path):\n",
    "        print('Loaded',jointgensit_intensity_mean_path)\n",
    "        jointgensit_intensity_mean = xr.open_dataarray(jointgensit_intensity_mean_path)\n",
    "\n",
    "else:\n",
    "\n",
    "    settings = {\n",
    "        \"logging_mode\": \"INFO\",\n",
    "        \"coordinate_slice\": [],\n",
    "        \"slice\":False,\n",
    "        \"metadata_keys\":[],\n",
    "        \"burnin_thinning_trimming\": [],#{'iter': {\"burnin\":10000, \"thinning\":1, \"trimming\":100000}}\n",
    "        \"sample\":[sample],\n",
    "        \"group_by\":[],\n",
    "        \"filename_ending\":\"test\",\n",
    "        \"force_reload\":True,\n",
    "        \"n_workers\": 1\n",
    "    }\n",
    "    jointgensit_table_mean_path = os.path.join(jointgensit_out_path,f'joint_gensit_{sample}_mean_E{n_ensemble}_N{n_iter}_sigma{sigma_str}.nc')\n",
    "\n",
    "    if (not os.path.exists(jointgensit_table_mean_path) or reload):\n",
    "        jointgensit_table_means = []\n",
    "        for seed in tqdm(seeds):\n",
    "            # Initialise outputs\n",
    "            jointgensit_outputs = Outputs(\n",
    "                config = f'../../data/outputs/DC/exp1/{experiment_id}/config.json',\n",
    "                settings = settings,\n",
    "                inputs = None,\n",
    "                slice = True,\n",
    "                level = 'NOTE'\n",
    "            )\n",
    "            # Silence outputs\n",
    "            jointgensit_outputs.logger.setLevels(console_level='NOTE')\n",
    "            # Slice sweep configurations\n",
    "            print(jointgensit_outputs.config.sweep_configurations)\n",
    "            jointgensit_outputs.config.sweep_configurations = [(seed,sigma, ['alpha', 'beta'])]\n",
    "            # Load all data\n",
    "            jointgensit_outputs.load()\n",
    "\n",
    "            # Get data from first sweep of the experiment\n",
    "            jointgensit_outputs = jointgensit_outputs.get(0)\n",
    "            \n",
    "            # Compute mean and add it to list\n",
    "            jointgensit_table_means.append(jointgensit_outputs.data.table.mean(['iter'],dtype='float64'))\n",
    "\n",
    "        # Compute mean across seeds\n",
    "        jointgensit_table_mean = xr.concat(\n",
    "            jointgensit_table_means, \n",
    "            dim='seed'\n",
    "        ).reset_index('sweep')\n",
    "        jointgensit_table_mean.to_netcdf(path=jointgensit_table_mean_path)\n",
    "\n",
    "    elif os.path.exists(jointgensit_table_mean_path):\n",
    "        print('Loaded',jointgensit_table_mean_path)\n",
    "        jointgensit_table_mean = xr.open_dataarray(jointgensit_table_mean_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e68141ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "if 'jointgensit_table_mean' in globals():\n",
    "    jointgensit_table_srmses = jointgensit_table_mean.groupby('seed').map(\n",
    "        srmse,\n",
    "        ground_truth = inputs.data.ground_truth_table,\n",
    "        mask = inputs.data.test_cells_mask\n",
    "    ).values\n",
    "    print(\"jointgensit_table_srmses\",np.mean(jointgensit_table_srmses),np.std(jointgensit_table_srmses))\n",
    "\n",
    "    joint_gensit_table_relative_l1_error = relative_l_1(\n",
    "        prediction=jointgensit_table_mean,\n",
    "        ground_truth=ground_truth_table,\n",
    "        mask=inputs.data.test_cells_mask,\n",
    "    )\n",
    "    print('Joint Gensit table: mean relative l1',joint_gensit_table_relative_l1_error.mean(['origin','destination','seed'],dtype='float64').values)\n",
    "\n",
    "    joint_gensit_table_relative_colsum_l1_error = mean_absolute_residual_percentage_error(\n",
    "        prediction=jointgensit_table_mean,\n",
    "        ground_truth=ground_truth_table,\n",
    "        mask=inputs.data.test_cells_mask,\n",
    "        dim='origin'\n",
    "    )\n",
    "    joint_gensit_table_relative_rowsum_l1_error = mean_absolute_residual_percentage_error(\n",
    "        prediction=jointgensit_table_mean,\n",
    "        ground_truth=ground_truth_table,\n",
    "        mask=inputs.data.test_cells_mask,\n",
    "        dim='destination'\n",
    "    )\n",
    "\n",
    "if 'jointgensit_intensity_mean' in globals():\n",
    "    jointgensit_intensity_srmses = jointgensit_intensity_mean.groupby('seed').map(\n",
    "        srmse,\n",
    "        ground_truth = inputs.data.ground_truth_table,\n",
    "        mask = inputs.data.test_cells_mask\n",
    "    ).values\n",
    "    print(\"jointgensit_intensity_srmses\",np.mean(jointgensit_intensity_srmses),np.std(jointgensit_intensity_srmses))\n",
    "\n",
    "    joint_gensit_intensity_relative_l1_error = relative_l_1(\n",
    "        prediction=jointgensit_intensity_mean,\n",
    "        ground_truth=ground_truth_table,\n",
    "        mask=inputs.data.test_cells_mask,\n",
    "    )\n",
    "    print('Joint Gensit intensity: mean relative l1',joint_gensit_intensity_relative_l1_error.mean(['origin','destination','seed'],dtype='float64').values)\n",
    "\n",
    "    joint_gensit_intensity_relative_colsum_l1_error = mean_absolute_residual_percentage_error(\n",
    "        prediction=jointgensit_intensity_mean,\n",
    "        ground_truth=ground_truth_table,\n",
    "        mask=inputs.data.test_cells_mask,\n",
    "        dim='origin'\n",
    "    )\n",
    "    joint_gensit_intensity_relative_rowsum_l1_error = mean_absolute_residual_percentage_error(\n",
    "        prediction=jointgensit_intensity_mean,\n",
    "        ground_truth=ground_truth_table,\n",
    "        mask=inputs.data.test_cells_mask,\n",
    "        dim='destination'\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "342ce711",
   "metadata": {},
   "outputs": [],
   "source": [
    "min(joint_gensit_table_relative_colsum_l1_error.values),max(joint_gensit_table_relative_colsum_l1_error.values),sum(joint_gensit_table_relative_colsum_l1_error.values)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f4c53656",
   "metadata": {},
   "source": [
    "# SIM_NN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "02d395e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "reload = False\n",
    "\n",
    "n_iter = 100000\n",
    "n_ensemble = 10\n",
    "seeds = range(1,11)\n",
    "sigma = 0.1414213562\n",
    "#0.1414213562, None, 0.0141421356\n",
    "\n",
    "experiment_id = 'SIM_NN_SweepedNoise__totally_and_cell_constrained_20_05_2024_15_59_08'\n",
    "sim_nn_out_path = f'../../data/outputs/DC/exp1/{experiment_id}/stored_results/'\n",
    "makedir(sim_nn_out_path)\n",
    "sigma_str = str(np.round(sigma,5) if sigma is not None else None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b445251c",
   "metadata": {},
   "outputs": [],
   "source": [
    "sim_nn_intensity_mean_path = os.path.join(sim_nn_out_path,f'sim_nn_intensity_mean_E{n_ensemble}_N{n_iter}_sigma{sigma_str}.nc')\n",
    "if (not os.path.exists(sim_nn_intensity_mean_path) or reload):\n",
    "    settings = {\n",
    "        \"logging_mode\": \"INFO\",\n",
    "        \"coordinate_slice\": [\n",
    "            f\"da.sigma=={sigma_str}\"\n",
    "        ],\n",
    "        \"slice\":True,\n",
    "        \"metadata_keys\":[],\n",
    "        \"burnin_thinning_trimming\": [],#{'iter': {\"burnin\":10000, \"thinning\":1, \"trimming\":100000}}\n",
    "        \"sample\":[\"intensity\"],\n",
    "        \"group_by\":[],\n",
    "        \"filename_ending\":\"test\",\n",
    "        \"force_reload\":False,\n",
    "        \"n_workers\": 1\n",
    "    }\n",
    "    # Initialise outputs\n",
    "    sim_nn_outputs = Outputs(\n",
    "        config = f'../../data/outputs/DC/exp1/{experiment_id}/config.json',\n",
    "        settings = settings,\n",
    "        inputs = None,\n",
    "        slice = True,\n",
    "        level = 'NOTE'\n",
    "    )\n",
    "    # Silence outputs\n",
    "    sim_nn_outputs.logger.setLevels(console_level='NOTE')\n",
    "    # Load all data\n",
    "    sim_nn_outputs.load()\n",
    "\n",
    "    # Get data from first sweep of the experiment\n",
    "    sim_nn_outputs = sim_nn_outputs.get(0)\n",
    "\n",
    "    # Compute \n",
    "    sim_nn_intensity_means = []\n",
    "    for s in tqdm(sim_nn_outputs.data.alpha.coords['seed'].values):\n",
    "        sim_nn_outputs_group = sim_nn_outputs.select('seed',s)\n",
    "        sim_nn_intensity_group = sim_nn_outputs_group.get_sample('intensity')\n",
    "        sim_nn_intensity_means.append(sim_nn_intensity_group.mean(['iter'],dtype='float64'))\n",
    "    sim_nn_intensity_mean = xr.concat(\n",
    "        sim_nn_intensity_means, \n",
    "        dim='seed'\n",
    "    ).reset_index('sweep')\n",
    "    sim_nn_intensity_mean.to_netcdf(path=sim_nn_intensity_mean_path)\n",
    "    sim_nn_intensity_mean = sim_nn_intensity_mean.squeeze('sweep')\n",
    "elif os.path.exists(sim_nn_intensity_mean_path):\n",
    "    print('Loaded',sim_nn_intensity_mean_path)\n",
    "    sim_nn_intensity_mean = xr.open_dataarray(sim_nn_intensity_mean_path)\n",
    "    sim_nn_intensity_mean = sim_nn_intensity_mean.squeeze('sweep')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37c155ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "if 'sim_nn_intensity_mean' in globals():\n",
    "    sim_nn_intensity_srmses = sim_nn_intensity_mean.groupby('seed').map(\n",
    "        srmse,\n",
    "        ground_truth = inputs.data.ground_truth_table,\n",
    "        mask = inputs.data.test_cells_mask\n",
    "    ).values\n",
    "\n",
    "    sim_nn_relative_l1_error = relative_l_1(\n",
    "        prediction=sim_nn_intensity_mean,\n",
    "        ground_truth=ground_truth_table,\n",
    "        mask=inputs.data.test_cells_mask,\n",
    "    )\n",
    "    print('SIM NN intensity: mean relative l1',sim_nn_relative_l1_error.mean(['origin','destination','seed'],dtype='float64').values)\n",
    "\n",
    "    sim_nn_relative_colsum_l1_error = mean_absolute_residual_percentage_error(\n",
    "        prediction=sim_nn_intensity_mean,\n",
    "        ground_truth=ground_truth_table,\n",
    "        mask=inputs.data.test_cells_mask,\n",
    "        dim='origin'\n",
    "    )\n",
    "    sim_nn_relative_rowsum_l1_error = mean_absolute_residual_percentage_error(\n",
    "        prediction=sim_nn_intensity_mean,\n",
    "        ground_truth=ground_truth_table,\n",
    "        mask=inputs.data.test_cells_mask,\n",
    "        dim='destination'\n",
    "    )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ebaefe0",
   "metadata": {},
   "outputs": [],
   "source": [
    "min(sim_nn_relative_colsum_l1_error.values),max(sim_nn_relative_colsum_l1_error.values),sum(sim_nn_relative_colsum_l1_error.values)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e803f1ef",
   "metadata": {},
   "source": [
    "# GMEL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48f5cead",
   "metadata": {},
   "outputs": [],
   "source": [
    "reload = False\n",
    "n_iter = 10000\n",
    "n_ensemble = 10 \n",
    "\n",
    "experiment_id = 'GraphAttentionNetwork_Comparison_UnsetNoise__doubly_and_cell_constrained_all_region_features_16_05_2024_21_06_14'\n",
    "gmel_out_path = f'../../data/outputs/DC/comparisons/{experiment_id}/stored_results/'\n",
    "makedir(gmel_out_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "043454cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "gmel_intensity_mean_path = f'../../data/outputs/DC/comparisons/{experiment_id}/stored_results/gmel_intensity_mean_E{n_ensemble}_N{n_iter}.nc'\n",
    "if (not os.path.exists(gmel_intensity_mean_path) or reload):\n",
    "    gmel_settings = {\n",
    "        \"logging_mode\": \"INFO\",\n",
    "        \"coordinate_slice\": [\n",
    "            # \"da.seed==1\"\n",
    "        ],\n",
    "        \"slice\":False,\n",
    "        \"metadata_keys\":[],\n",
    "        \"burnin_thinning_trimming\": [],\n",
    "        \"sample\":[\"intensity\"],\n",
    "        \"group_by\":[],\n",
    "        \"filename_ending\":\"test\",\n",
    "        \"force_reload\":False,\n",
    "        \"n_workers\": 1\n",
    "    }\n",
    "\n",
    "    # Initialise outputs\n",
    "    gmel_outputs = Outputs(\n",
    "        config = f'../../data/outputs/DC/comparisons/{experiment_id}/config.json',\n",
    "        settings = gmel_settings,\n",
    "        inputs = None,\n",
    "        slice = True,\n",
    "        level = 'NOTE'\n",
    "    )\n",
    "    # Silence outputs\n",
    "    gmel_outputs.logger.setLevels(console_level='NOTE')\n",
    "    # Load all data\n",
    "    gmel_outputs.load()\n",
    "\n",
    "    # Get data from first sweep of the experiment\n",
    "    gmel_outputs = gmel_outputs.get(0)\n",
    "\n",
    "    makedir(os.path.dirname(gmel_intensity_mean_path))\n",
    "    gmel_intensity_mean = gmel_outputs.data.intensity.mean(['iter'],dtype='float64')\n",
    "    gmel_intensity_mean.to_netcdf(path=gmel_intensity_mean_path)\n",
    "else:\n",
    "    gmel_intensity_mean = xr.open_dataarray(gmel_intensity_mean_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7abc88d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "if 'gmel_intensity_mean' in globals():\n",
    "    gmel_srmses = gmel_intensity_mean.groupby('seed').apply(\n",
    "        srmse,\n",
    "        ground_truth = inputs.data.ground_truth_table,\n",
    "        mask = inputs.data.test_cells_mask\n",
    "    ).values\n",
    "\n",
    "    gmel_relative_l1_error = relative_l_1(\n",
    "        prediction=gmel_intensity_mean,\n",
    "        ground_truth=ground_truth_table,\n",
    "        mask=inputs.data.test_cells_mask,\n",
    "    )\n",
    "    print('GMEL intensity: mean relative l1',gmel_relative_l1_error.mean(['origin','destination','seed'],dtype='float64').values)\n",
    "\n",
    "    gmel_relative_colsum_l1_error = mean_absolute_residual_percentage_error(\n",
    "        prediction=gmel_intensity_mean,\n",
    "        ground_truth=ground_truth_table,\n",
    "        mask=inputs.data.test_cells_mask,\n",
    "        dim='origin'\n",
    "    )\n",
    "    gmel_relative_rowsum_l1_error = mean_absolute_residual_percentage_error(\n",
    "        prediction=gmel_intensity_mean,\n",
    "        ground_truth=ground_truth_table,\n",
    "        mask=inputs.data.test_cells_mask,\n",
    "        dim='destination'\n",
    "    )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f07e28b",
   "metadata": {},
   "outputs": [],
   "source": [
    "min(gmel_relative_colsum_l1_error.values),max(gmel_relative_colsum_l1_error.values),sum(gmel_relative_colsum_l1_error.values)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ecbda455",
   "metadata": {},
   "source": [
    "# Plots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cfeac10e",
   "metadata": {},
   "outputs": [],
   "source": [
    "for sum_dim in ['origin','destination']:\n",
    "    region_geometries = getattr(inputs.data,'region_geometries')\n",
    "\n",
    "    if sum_dim == 'destination':\n",
    "        plot_dim = 'origin'\n",
    "        gmel_quantity = gmel_relative_rowsum_l1_error\n",
    "        sim_nn_quantity = sim_nn_relative_rowsum_l1_error\n",
    "        joint_gensit_quantity = joint_gensit_table_relative_rowsum_l1_error\n",
    "\n",
    "    elif sum_dim == 'origin':\n",
    "        plot_dim = 'destination'\n",
    "        gmel_quantity = gmel_relative_colsum_l1_error\n",
    "        sim_nn_quantity = sim_nn_relative_colsum_l1_error\n",
    "        joint_gensit_quantity = joint_gensit_table_relative_colsum_l1_error\n",
    "\n",
    "    min_error = min(np.min(gmel_quantity.values),np.min(sim_nn_quantity.values),np.min(joint_gensit_quantity.values))\n",
    "    max_error = max(np.max(gmel_quantity.values),np.max(sim_nn_quantity.values),np.max(joint_gensit_quantity.values))\n",
    "\n",
    "    if 'joint_gensit_quantity' in globals():\n",
    "        print(f\"Joint GeNSIT min error: {np.min(joint_gensit_quantity.values)} max error: {np.max(joint_gensit_quantity.values)} total error: {np.sum(joint_gensit_quantity.values)}\")\n",
    "    if 'sim_nn_quantity' in globals():\n",
    "        print(f\"SIM NN min error: {np.min(sim_nn_quantity.values)} max error: {np.max(sim_nn_quantity.values)} total error: {np.sum(sim_nn_quantity.values)}\")\n",
    "    if 'gmel_quantity' in globals():\n",
    "        print(f\"GMEL min error: {np.min(gmel_quantity.values)} max error: {np.max(gmel_quantity.values)} total abs error: {np.sum(gmel_quantity.values)}\")\n",
    "\n",
    "    gmel_quantity_with_geometries = pd.merge(\n",
    "        gmel_quantity.to_pandas().reset_index().rename(columns={0:\"error\"}),\n",
    "        region_geometries[['LOCATIONID','geometry']],\n",
    "        how = 'left',\n",
    "        left_on = plot_dim,\n",
    "        right_on = 'LOCATIONID'\n",
    "    ) \n",
    "    # Convert back to geodataframe\n",
    "    gmel_quantity_with_geometries = gpd.GeoDataFrame(gmel_quantity_with_geometries.drop(columns=['LOCATIONID']))\n",
    "\n",
    "    joint_gensit_quantity_with_geometries = pd.merge(\n",
    "        joint_gensit_quantity.to_pandas().reset_index().rename(columns={0:\"error\"}),\n",
    "        region_geometries[['LOCATIONID','geometry']],\n",
    "        how = 'left',\n",
    "        left_on = plot_dim,\n",
    "        right_on = 'LOCATIONID'\n",
    "    ) \n",
    "    # Convert back to geodataframe\n",
    "    joint_gensit_quantity_with_geometries = gpd.GeoDataFrame(joint_gensit_quantity_with_geometries.drop(columns=['LOCATIONID']))\n",
    "\n",
    "\n",
    "    sim_nn_quantity_with_geometries = pd.merge(\n",
    "        sim_nn_quantity.to_pandas().reset_index().rename(columns={0:\"error\"}),\n",
    "        region_geometries[['LOCATIONID','geometry']],\n",
    "        how = 'left',\n",
    "        left_on = plot_dim,\n",
    "        right_on = 'LOCATIONID'\n",
    "    ) \n",
    "    # Convert back to geodataframe\n",
    "    sim_nn_quantity_with_geometries = gpd.GeoDataFrame(sim_nn_quantity_with_geometries.drop(columns=['LOCATIONID']))\n",
    "\n",
    "    # Plot settings\n",
    "    plot_settings = {\n",
    "        \"figure_size\":(10,10),\n",
    "        \"colourmap\":\"Reds\",\n",
    "        \"figure_format\":\"ps\",\n",
    "        \"figure_title\":\"figure5/mean_residual\",\n",
    "        \"legend_axis\":[0,0],\n",
    "        \"axis_title_size\":30,\n",
    "        \n",
    "        \"x_label\":\"Longitude\",\n",
    "        \"x_label_size\":18,\n",
    "        \"x_label_pad\":7,\n",
    "        \"x_tick_size\":16,\n",
    "        \"x_tick_rotation\":None,\n",
    "        \"x_tick_pad\":5,\n",
    "        \"x_label_rotation\":0,\n",
    "        \n",
    "        \"y_label\":\"Latitude\",\n",
    "        \"y_label_size\":18,\n",
    "        \"y_label_pad\":7,\n",
    "        \"y_tick_size\":16,\n",
    "        \"y_tick_rotation\":None,\n",
    "        \"y_tick_pad\":5,\n",
    "        \"y_label_rotation\":90,\n",
    "        \n",
    "        \"vmin\":0.08,#min_error,\n",
    "        \"vmax\":28,#max_error,\n",
    "        \"colourbar\":False\n",
    "    }\n",
    "\n",
    "    for model,data in [\n",
    "        (\"GMEL\",gmel_quantity_with_geometries),\n",
    "        (\"SIM NN\",sim_nn_quantity_with_geometries),\n",
    "        (\"GeNSIT (Joint)\",joint_gensit_quantity_with_geometries),\n",
    "        \n",
    "    ]:\n",
    "        \n",
    "        print(f\"Compiling figure for {model} over {plot_dim}s\")\n",
    "        # Figure size \n",
    "        fig, ax = plt.subplots(\n",
    "            figsize = plot_settings.get('figure_size',None),\n",
    "            ncols = 1,\n",
    "            nrows = 1,\n",
    "            squeeze = False\n",
    "        )\n",
    "\n",
    "        # Set colormap\n",
    "        cmap = plt.get_cmap(plot_settings.get('colourmap',None))\n",
    "        norm = mpl.colors.LogNorm(vmin=plot_settings[\"vmin\"], vmax=plot_settings[\"vmax\"])\n",
    "\n",
    "        # Global axes label\n",
    "        for var in ['x','y']:\n",
    "            if plot_settings.get(f'{var}_label',''):\n",
    "                axis_label = plot_settings[f'{var}_label'].replace(\"_\",\" \")\n",
    "                getattr(plt,f\"{var}label\",plt.xlabel)(\n",
    "                    axis_label,\n",
    "                    fontsize = plot_settings.get(f'{var}_label_size',None),\n",
    "                    labelpad = plot_settings.get(f'{var}_label_pad',None),\n",
    "                    rotation = plot_settings.get(f'{var}_label_rotation',None)\n",
    "                )\n",
    "                ax[0,0].tick_params(\n",
    "                    axis = var, \n",
    "                    pad = plot_settings.get(f\"{var}_tick_pad\",None),\n",
    "                    bottom = True,\n",
    "                    labelsize = plot_settings.get(f\"{var}_tick_size\",None),\n",
    "                    rotation = plot_settings.get(f\"{var}_tick_rotation\",None)\n",
    "                )\n",
    "        ax[0,0] = data.plot(\n",
    "                column = 'error',\n",
    "                ax = ax[0,0],\n",
    "                alpha = 1,\n",
    "                markersize = 2.0,\n",
    "                linewidth=2, \n",
    "                edgecolor='black',\n",
    "                cmap = cmap,\n",
    "                # norm = mpl.colors.Normalize(vmin=plot_settings[\"vmin\"], vmax=plot_settings[\"vmax\"]),\n",
    "                norm = norm,\n",
    "                legend = plot_settings['colourbar']\n",
    "            )\n",
    "        # ax[0,0].set_title(\n",
    "        #     model,\n",
    "        #     fontdict = {'fontsize':plot_settings.get('axis_title_size',None)}\n",
    "        # )\n",
    "        if sum_dim == 'origin':\n",
    "            text_loc = (0.7, 0.87)\n",
    "        else:\n",
    "            text_loc = (0.8, 0.87)\n",
    "        fig.text(\n",
    "            text_loc[0], text_loc[1], f\"Mean abs. \\% error: {np.round(data.error.mean(),1)}\", \n",
    "            ha='right', va='top', fontsize=22, \n",
    "            bbox=dict(facecolor='none', edgecolor='none', alpha=0)\n",
    "        )\n",
    "        ax[0,0].tick_params(labelsize=plot_settings['x_tick_size'])\n",
    "        if len(ax[0,0].get_figure().get_axes()) > 1:\n",
    "            # Access the colorbar\n",
    "            cbar = ax[0,0].get_figure().get_axes()[1]\n",
    "            # Set the fontsize of the colorbar\n",
    "            cbar.tick_params(labelsize=plot_settings['x_tick_size'])\n",
    "\n",
    "        write_figure(\n",
    "            fig,\n",
    "            f\"../../data/outputs/DC/exp1/paper_figures/residuals/{model}_{plot_dim}\",\n",
    "            figure_format=plot_settings.get('figure_format',''),\n",
    "            pad_inches=0.0,\n",
    "            bbox_inches='tight'\n",
    "        )\n",
    "\n",
    "    # Create a separate figure for horizontal colorbar\n",
    "    fig_cbar, ax_cbar = plt.subplots(figsize=(8, 1))  # Wide and short\n",
    "\n",
    "    print(f'{sum_dim} sum','vmin',plot_settings['vmin'],'vmax',plot_settings['vmax'])\n",
    "    # Use same colormap and normalization as main plot\n",
    "    sm = mpl.cm.ScalarMappable(cmap=cmap, norm=norm)\n",
    "    sm.set_array([])  # Required for colorbar creation in older versions\n",
    "\n",
    "    # Create horizontal colorbar\n",
    "    cbar = fig_cbar.colorbar(sm, cax=ax_cbar, orientation='horizontal')\n",
    "    cbar.ax.tick_params(labelsize=plot_settings['x_tick_size'])\n",
    "\n",
    "    # Optional: customize labels or add title\n",
    "    # cbar.set_label(\"Error Value\", fontsize=14)\n",
    "\n",
    "    # Clean layout\n",
    "    fig_cbar.tight_layout()\n",
    "\n",
    "    write_figure(\n",
    "        fig_cbar,\n",
    "        f\"../../data/outputs/DC/exp1/paper_figures/residuals/{plot_dim}_colorbar\",\n",
    "        figure_format=plot_settings.get('figure_format',''),\n",
    "        pad_inches=0.0,\n",
    "        bbox_inches='tight'\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ebe31c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sanity check\n",
    "(inputs.data.train_cells.shape[0] + \\\n",
    "inputs.data.test_cells.shape[0] + \\\n",
    "inputs.data.validation_cells.shape[0]) \\\n",
    "== \\\n",
    "ground_truth_table.shape[0]*ground_truth_table.shape[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba82f2a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot train / test / validation split\n",
    "table_masks = deepcopy(ground_truth_table)\n",
    "table_masks[:] = 0\n",
    "table_masks += inputs.data.train_cells_mask.astype(int)\n",
    "table_masks += 2*inputs.data.test_cells_mask.astype(int)\n",
    "table_masks += 3*inputs.data.validation_cells_mask.astype(int)\n",
    "\n",
    "new_destinations = np.where(np.all(table_masks == 2, axis=0))[0]\n",
    "new_origins = np.where(np.all(table_masks == 2, axis=1))[0]\n",
    "# print('new destinations',new_destinations)\n",
    "# print('new origins',new_origins)\n",
    "print(\"Total test destinations\",len(np.unique(inputs.data.test_cells[:,0])))\n",
    "print(\"Total test origins\",len(np.unique(inputs.data.test_cells[:,1])))\n",
    "\n",
    "test_cells_df = pd.DataFrame(inputs.data.test_cells.astype(int), columns=[\"origin\", \"destination\"])\n",
    "# Count unique values in column 2 (value) per unique value in column 1 (key)\n",
    "# print(\"Total test origins by test destination\",test_cells_df.groupby(\"origin\")[\"destination\"].nunique())\n",
    "# print(\"Total test destinations by test origin\",test_cells_df.groupby(\"destination\")[\"origin\"].nunique())\n",
    "\n",
    "fig,ax = plt.subplots(1,1,figsize=(10, 10))\n",
    "colors = ['green', 'red', 'blue']\n",
    "cmap = mpl.colors.ListedColormap(colors)\n",
    "heatmap = plt.imshow(table_masks, cmap=cmap, aspect='equal', interpolation='nearest')\n",
    "cbar = plt.colorbar(ticks=[1, 2, 3],fraction=0.046, pad=0.04)\n",
    "cbar.set_ticklabels(['Train', 'Test', 'Validation'])\n",
    "cbar.ax.tick_params(labelsize=14)\n",
    "# ax.set_xticks([])\n",
    "# ax.set_yticks([])\n",
    "ax.tick_params(axis='both', labelsize=14)\n",
    "ax.set_xlabel('Destinations', fontsize=16)\n",
    "ax.set_ylabel('Origins', fontsize=16)\n",
    "# fig.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "fig.savefig(\n",
    "    f\"../../data/outputs/DC/exp1/paper_figures/train_test_split/train_test_validation_split.pdf\",\n",
    "    format='pdf'\n",
    ")\n",
    "# write_figure(\n",
    "#     fig,\n",
    "#     f\"../../data/outputs/DC/exp1/paper_figures/train_test_split/train_test_validation_split\",\n",
    "#     figure_format=plot_settings.get('figure_format',''),\n",
    "#     pad_inches=0.0,\n",
    "#     bbox_inches='tight'\n",
    "# )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a6028504",
   "metadata": {},
   "outputs": [],
   "source": [
    "# fig,ax = plt.subplots(1,1,figsize=(10, 10))\n",
    "# plt.title('New destinations')\n",
    "# region_geometries.boundary.plot(ax=ax)\n",
    "# region_geometries[region_geometries.LOCATIONID.isin(new_destinations)].plot(ax=ax,color='red', edgecolor='black')\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "db629917",
   "metadata": {},
   "source": [
    "# Statistical significance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19a4b328",
   "metadata": {},
   "outputs": [],
   "source": [
    "print('GMEL',np.mean(gmel_srmses),np.std(gmel_srmses))\n",
    "# print('SIM_NN',np.mean(sim_nn_intensity_srmses),np.std(sim_nn_intensity_srmses))\n",
    "print('Joint GeNSIT',np.mean(jointgensit_table_srmses),np.std(jointgensit_table_srmses))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bea4c62d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# HO: mean(Joint GeNSIT SRMSE) >= mean(GMEL SRMSE)\n",
    "perform_one_tailed_ttest(\n",
    "    sample_a_name='GeNSIT (Joint) SRMSE',\n",
    "    sample_a=jointgensit_table_srmses,\n",
    "    sample_b_name='GMEL SRMSE',\n",
    "    sample_b=gmel_srmses,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b47ff3ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "perform_one_tailed_ttest_using_summaries(\n",
    "    name1 = 'GeNSIT (Joint) SRMSE',\n",
    "    mean1 = np.mean(jointgensit_table_srmses),\n",
    "    std1 = np.std(jointgensit_table_srmses),\n",
    "    n1=20,\n",
    "    name2 = 'GMEL SRMSE',\n",
    "    mean2 = np.mean(gmel_srmses), \n",
    "    std2 = np.std(gmel_srmses),\n",
    "    n2=20,\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "gensit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

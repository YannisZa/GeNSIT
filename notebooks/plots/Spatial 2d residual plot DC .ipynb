{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c76b8620",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import glob\n",
    "import warnings\n",
    "import h5py as h5\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib as mpl\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.colors as mcolors\n",
    "\n",
    "from tqdm.auto import tqdm\n",
    "from copy import deepcopy\n",
    "\n",
    "from gensit.config import Config\n",
    "from gensit.inputs import Inputs\n",
    "from gensit.outputs import Outputs\n",
    "from gensit.utils.misc_utils import *\n",
    "from gensit.utils.math_utils import *\n",
    "from gensit.utils.probability_utils import *\n",
    "from gensit.contingency_table import instantiate_ct\n",
    "from gensit.contingency_table.MarkovBasis import instantiate_markov_basis\n",
    "from gensit.static.plot_variables import LATEX_RC_PARAMETERS, COLOR_NAMES"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b718b815",
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "\n",
    "# AUTO RELOAD EXTERNAL MODULES\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d610efec",
   "metadata": {},
   "outputs": [],
   "source": [
    "# LaTeX font configuration\n",
    "mpl.rcParams.update(LATEX_RC_PARAMETERS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "188d0194",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create new logging object\n",
    "logger = setup_logger(\n",
    "    __name__,\n",
    "    console_level = 'INFO',\n",
    "    file_level = 'EMPTY'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "494e6140",
   "metadata": {},
   "outputs": [],
   "source": [
    "config = Config(\n",
    "    \"../../data/inputs/configs/DC/vanilla_comparisons.toml\"\n",
    ")\n",
    "inputs = Inputs(\n",
    "    config = config,\n",
    "    synthetic_data = False,\n",
    "    logger = logger\n",
    ")\n",
    "inputs.cast_to_xarray()\n",
    "ground_truth_table = inputs.data.ground_truth_table"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "823801b3",
   "metadata": {},
   "source": [
    "# GeNSIT (Disjoint)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "0d46d4c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "sample = \"table\"\n",
    "reload = False\n",
    "\n",
    "n_iter = 100000\n",
    "n_ensemble = 10\n",
    "seeds = range(1,11)\n",
    "sigma = 0.1414213562\n",
    "#0.1414213562, None, 0.0141421356\n",
    "\n",
    "experiment_id = \"NonJointTableSIM_NN_SweepedNoise__totally_and_cell_constrained_20_05_2024_15_57_08\"\n",
    "disjointgensit_out_path = f'../../data/outputs/DC/exp1/{experiment_id}/stored_results/'\n",
    "makedir(disjointgensit_out_path)\n",
    "sigma_str = str(np.round(sigma,5) if sigma is not None else None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "6112099b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded ../../data/outputs/DC/exp1/NonJointTableSIM_NN_SweepedNoise__totally_and_cell_constrained_20_05_2024_15_57_08/stored_results/disjoint_gensit_table_mean_E10_N100000_sigma0.14142.nc\n"
     ]
    }
   ],
   "source": [
    "if sample == \"intensity\":\n",
    "    settings = {\n",
    "        \"logging_mode\": \"INFO\",\n",
    "        \"coordinate_slice\": [\n",
    "            f\"da.sigma=={sigma_str}\"\n",
    "        ],\n",
    "        \"slice\":True,\n",
    "        \"metadata_keys\":[],\n",
    "        \"burnin_thinning_trimming\": [],#{'iter': {\"burnin\":10000, \"thinning\":1, \"trimming\":100000}}\n",
    "        \"sample\":[sample],\n",
    "        \"group_by\":[],\n",
    "        \"filename_ending\":\"test\",\n",
    "        \"force_reload\":False,\n",
    "        \"n_workers\": 1\n",
    "    }\n",
    "        \n",
    "    disjointgensit_intensity_mean_path = os.path.join(disjointgensit_out_path,f'disjoint_gensit_{sample}_mean_E{n_ensemble}_N{n_iter}_sigma{sigma_str}.nc')\n",
    "    if (not os.path.exists(disjointgensit_intensity_mean_path) or reload):\n",
    "        # Initialise outputs\n",
    "        disjointgensit_outputs = Outputs(\n",
    "            config = f'../../data/outputs/DC/exp1/{experiment_id}/config.json',\n",
    "            settings = settings,\n",
    "            inputs = None,\n",
    "            slice = True,\n",
    "            level = 'NOTE'\n",
    "        )\n",
    "        # Silence outputs\n",
    "        disjointgensit_outputs.logger.setLevels(console_level='NOTE')\n",
    "        # Load all data\n",
    "        disjointgensit_outputs.load()\n",
    "\n",
    "        # Get data from first sweep of the experiment\n",
    "        disjointgensit_outputs = disjointgensit_outputs.get(0)\n",
    "\n",
    "        # Compute \n",
    "        disjointgensit_intensity_means = []\n",
    "        for s in tqdm(disjointgensit_outputs.data.alpha.coords['seed'].values):\n",
    "            disjointgensit_outputs_group = disjointgensit_outputs.select('seed',s)\n",
    "            disjointgensit_intensity_group = disjointgensit_outputs_group.get_sample('intensity')\n",
    "            disjointgensit_intensity_means.append(disjointgensit_intensity_group.mean(['iter'],dtype='float64'))\n",
    "        disjointgensit_intensity_mean = xr.concat(\n",
    "            disjointgensit_intensity_means, \n",
    "            dim='seed',\n",
    "            coords=disjointgensit_outputs.data.alpha.coords['seed'].values\n",
    "        ).reset_index('sweep')\n",
    "        disjointgensit_intensity_mean.to_netcdf(path=disjointgensit_intensity_mean_path)\n",
    "    elif os.path.exists(disjointgensit_intensity_mean_path):\n",
    "        print('Loaded',disjointgensit_intensity_mean_path)\n",
    "        disjointgensit_intensity_mean = xr.open_dataarray(disjointgensit_intensity_mean_path)\n",
    "\n",
    "else:\n",
    "\n",
    "    settings = {\n",
    "        \"logging_mode\": \"INFO\",\n",
    "        \"coordinate_slice\": [],\n",
    "        \"slice\":False,\n",
    "        \"metadata_keys\":[],\n",
    "        \"burnin_thinning_trimming\": [],#{'iter': {\"burnin\":10000, \"thinning\":1, \"trimming\":100000}}\n",
    "        \"sample\":[sample],\n",
    "        \"group_by\":[],\n",
    "        \"filename_ending\":\"test\",\n",
    "        \"force_reload\":True,\n",
    "        \"n_workers\": 1\n",
    "    }\n",
    "    disjointgensit_table_mean_path = os.path.join(disjointgensit_out_path,f'disjoint_gensit_{sample}_mean_E{n_ensemble}_N{n_iter}_sigma{sigma_str}.nc')\n",
    "\n",
    "    if (not os.path.exists(disjointgensit_table_mean_path) or reload):\n",
    "        disjointgensit_table_means = []\n",
    "        for seed in tqdm(seeds):\n",
    "            # Initialise outputs\n",
    "            disjointgensit_outputs = Outputs(\n",
    "                config = f'../../data/outputs/DC/exp1/{experiment_id}/config.json',\n",
    "                settings = settings,\n",
    "                inputs = None,\n",
    "                slice = True,\n",
    "                level = 'NOTE'\n",
    "            )\n",
    "            # Silence outputs\n",
    "            disjointgensit_outputs.logger.setLevels(console_level='NOTE')\n",
    "            # Slice sweep configurations\n",
    "            print(disjointgensit_outputs.config.sweep_configurations)\n",
    "            disjointgensit_outputs.config.sweep_configurations = [(seed,sigma, ['alpha', 'beta'])]\n",
    "            # Load all data\n",
    "            disjointgensit_outputs.load()\n",
    "\n",
    "            # Get data from first sweep of the experiment\n",
    "            disjointgensit_outputs = disjointgensit_outputs.get(0)\n",
    "            \n",
    "            # Compute mean and add it to list\n",
    "            disjointgensit_table_means.append(disjointgensit_outputs.data.table.mean(['iter'],dtype='float64'))\n",
    "\n",
    "        # Compute mean across seeds\n",
    "        disjointgensit_table_mean = xr.concat(\n",
    "            disjointgensit_table_means, \n",
    "            dim='seed'\n",
    "        ).reset_index('sweep')\n",
    "        disjointgensit_table_mean.to_netcdf(path=disjointgensit_table_mean_path)\n",
    "\n",
    "    elif os.path.exists(disjointgensit_table_mean_path):\n",
    "        print('Loaded',disjointgensit_table_mean_path)\n",
    "        disjointgensit_table_mean = xr.open_dataarray(disjointgensit_table_mean_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "11f77d48",
   "metadata": {},
   "outputs": [],
   "source": [
    "if 'disjointgensit_table_mean' in globals():\n",
    "    disjointgensit_table_srmses = disjointgensit_table_mean.groupby('seed').map(\n",
    "        srmse,\n",
    "        ground_truth = inputs.data.ground_truth_table,\n",
    "        mask = inputs.data.test_cells_mask\n",
    "    ).values\n",
    "if 'disjointgensit_intensity_mean' in globals():\n",
    "    disjointgensit_intensity_srmses = disjointgensit_intensity_mean.groupby('seed').map(\n",
    "        srmse,\n",
    "        ground_truth = inputs.data.ground_truth_table,\n",
    "        mask = inputs.data.test_cells_mask\n",
    "    ).values"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "880cdfcb",
   "metadata": {},
   "source": [
    "# GeNSIT (Joint)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "477ed482",
   "metadata": {},
   "outputs": [],
   "source": [
    "sample = \"table\"\n",
    "reload = False\n",
    "\n",
    "n_iter = 100000\n",
    "n_ensemble = 1\n",
    "seeds = None#range(1,n_ensemble+1)\n",
    "sigma = 0.1414213562\n",
    "#0.1414213562, None, 0.0141421356\n",
    "\n",
    "experiment_id = 'JointTableSIM_NN_SweepedNoise__totally_and_cell_constrained_21_05_2024_13_25_40'\n",
    "jointgensit_out_path = f'../../data/outputs/DC/exp1/{experiment_id}/stored_results/'\n",
    "makedir(jointgensit_out_path)\n",
    "sigma_str = str(np.round(sigma,5) if sigma is not None else None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "833a9fad",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded ../../data/outputs/DC/exp1/JointTableSIM_NN_SweepedNoise__totally_and_cell_constrained_21_05_2024_13_25_40/stored_results/joint_gensit_table_mean_E1_N100000_sigma0.14142.nc\n"
     ]
    }
   ],
   "source": [
    "if sample == \"intensity\":\n",
    "    settings = {\n",
    "        \"logging_mode\": \"INFO\",\n",
    "        \"coordinate_slice\": [\n",
    "            f\"da.sigma=={sigma_str}\"\n",
    "        ],\n",
    "        \"slice\":True,\n",
    "        \"metadata_keys\":[],\n",
    "        \"burnin_thinning_trimming\": [],#{'iter': {\"burnin\":10000, \"thinning\":1, \"trimming\":100000}}\n",
    "        \"sample\":[sample],\n",
    "        \"group_by\":[],\n",
    "        \"filename_ending\":\"test\",\n",
    "        \"force_reload\":False,\n",
    "        \"n_workers\": 1\n",
    "    }\n",
    "\n",
    "    jointgensit_intensity_mean_path = os.path.join(jointgensit_out_path,f'joint_gensit_{sample}_mean_E{n_ensemble}_N{n_iter}_sigma{sigma_str}.nc')\n",
    "    if (not os.path.exists(jointgensit_intensity_mean_path) or reload):\n",
    "        # Initialise outputs\n",
    "        jointgensit_outputs = Outputs(\n",
    "            config = f'../../data/outputs/DC/exp1/{experiment_id}/config.json',\n",
    "            settings = settings,\n",
    "            inputs = None,\n",
    "            slice = True,\n",
    "            level = 'NOTE'\n",
    "        )\n",
    "        # Silence outputs\n",
    "        jointgensit_outputs.logger.setLevels(console_level='NOTE')\n",
    "        # Load all data\n",
    "        jointgensit_outputs.load()\n",
    "\n",
    "        # Get data from first sweep of the experiment\n",
    "        jointgensit_outputs = jointgensit_outputs.get(0)\n",
    "\n",
    "        # Compute \n",
    "        jointgensit_intensity_means = []\n",
    "        for s in tqdm(jointgensit_outputs.data.alpha.coords['seed'].values):\n",
    "            jointgensit_outputs_group = jointgensit_outputs.select('seed',s)\n",
    "            jointgensit_intensity_group = jointgensit_outputs_group.get_sample('intensity')\n",
    "            jointgensit_intensity_means.append(jointgensit_intensity_group.mean(['iter'],dtype='float64'))\n",
    "        jointgensit_intensity_mean = xr.concat(\n",
    "            jointgensit_intensity_means, \n",
    "            dim='seed',\n",
    "            coords=jointgensit_outputs.data.alpha.coords['seed'].values\n",
    "        ).reset_index('sweep')\n",
    "        jointgensit_intensity_mean.to_netcdf(path=jointgensit_intensity_mean_path)\n",
    "    elif os.path.exists(jointgensit_intensity_mean_path):\n",
    "        print('Loaded',jointgensit_intensity_mean_path)\n",
    "        jointgensit_intensity_mean = xr.open_dataarray(jointgensit_intensity_mean_path)\n",
    "\n",
    "else:\n",
    "\n",
    "    settings = {\n",
    "        \"logging_mode\": \"INFO\",\n",
    "        \"coordinate_slice\": [],\n",
    "        \"slice\":False,\n",
    "        \"metadata_keys\":[],\n",
    "        \"burnin_thinning_trimming\": [],#{'iter': {\"burnin\":10000, \"thinning\":1, \"trimming\":100000}}\n",
    "        \"sample\":[sample],\n",
    "        \"group_by\":[],\n",
    "        \"filename_ending\":\"test\",\n",
    "        \"force_reload\":True,\n",
    "        \"n_workers\": 1\n",
    "    }\n",
    "    jointgensit_table_mean_path = os.path.join(jointgensit_out_path,f'joint_gensit_{sample}_mean_E{n_ensemble}_N{n_iter}_sigma{sigma_str}.nc')\n",
    "\n",
    "    if (not os.path.exists(jointgensit_table_mean_path) or reload):\n",
    "        jointgensit_table_means = []\n",
    "        if seeds is not None:\n",
    "            for seed in tqdm(seeds):\n",
    "                # Initialise outputs\n",
    "                jointgensit_outputs = Outputs(\n",
    "                    config = f'../../data/outputs/DC/exp1/{experiment_id}/config.json',\n",
    "                    settings = settings,\n",
    "                    inputs = None,\n",
    "                    slice = True,\n",
    "                    level = 'NOTE'\n",
    "                )\n",
    "                # Silence outputs\n",
    "                jointgensit_outputs.logger.setLevels(console_level='NOTE')\n",
    "                # Slice sweep configurations\n",
    "                print(jointgensit_outputs.config.sweep_configurations)\n",
    "                jointgensit_outputs.config.sweep_configurations = [(seed,sigma, ['alpha', 'beta'])]\n",
    "                # Load all data\n",
    "                jointgensit_outputs.load()\n",
    "\n",
    "                # Get data from first sweep of the experiment\n",
    "                jointgensit_outputs = jointgensit_outputs.get(0)\n",
    "                \n",
    "                # Compute mean and add it to list\n",
    "                jointgensit_table_means.append(jointgensit_outputs.data.table.mean(['iter'],dtype='float64'))\n",
    "\n",
    "            # Compute mean across seeds\n",
    "            jointgensit_table_mean = xr.concat(\n",
    "                jointgensit_table_means, \n",
    "                dim='seed'\n",
    "            ).reset_index('sweep')\n",
    "            jointgensit_table_mean.to_netcdf(path=jointgensit_table_mean_path)\n",
    "        else:\n",
    "            settings = {\n",
    "                \"logging_mode\": \"INFO\",\n",
    "                \"coordinate_slice\": [\n",
    "                    \"da.loss_name==str(['dest_attraction_ts_likelihood_loss', 'table_likelihood_loss'])\",\n",
    "                    f\"da.sigma=={sigma_str}\"\n",
    "                ],\n",
    "                \"slice\":True,\n",
    "                \"metadata_keys\":[],\n",
    "                \"burnin_thinning_trimming\": [],#{'iter': {\"burnin\":10000, \"thinning\":1, \"trimming\":100000}}\n",
    "                \"sample\":[sample],\n",
    "                \"group_by\":[],\n",
    "                \"filename_ending\":\"test\",\n",
    "                \"force_reload\":False,\n",
    "                \"n_workers\": 1\n",
    "            }\n",
    "            # Initialise outputs\n",
    "            jointgensit_outputs = Outputs(\n",
    "                config = f'../../data/outputs/DC/exp1/{experiment_id}/config.json',\n",
    "                settings = settings,\n",
    "                inputs = None,\n",
    "                slice = True,\n",
    "                level = 'NOTE'\n",
    "            )\n",
    "            # Silence outputs\n",
    "            jointgensit_outputs.logger.setLevels(console_level='NOTE')\n",
    "            # Load all data\n",
    "            jointgensit_outputs.load()\n",
    "\n",
    "            # Get data from first sweep of the experiment\n",
    "            jointgensit_outputs = jointgensit_outputs.get(0)\n",
    "\n",
    "            jointgensit_table = jointgensit_outputs.data.table.squeeze('sweep')\n",
    "            new_n_seed = 10\n",
    "            new_n_iter = 10000\n",
    "            jointgensit_table_reshaped = jointgensit_table.values.reshape((new_n_seed,new_n_iter,jointgensit_table.sizes['origin'],jointgensit_table.sizes['destination']))\n",
    "            jointgensit_table_reshaped = xr.DataArray(\n",
    "                data = jointgensit_table_reshaped,\n",
    "                dims=[\"seed\", \"iter\", \"origin\", \"destination\"],\n",
    "                coords={\n",
    "                    \"seed\": np.arange(1, new_n_seed+1),\n",
    "                    \"iter\": np.arange(1, new_n_iter+1),\n",
    "                    \"origin\": np.arange(1, jointgensit_table.sizes['origin']+1),\n",
    "                    \"destination\": np.arange(1, jointgensit_table.sizes['destination']+1),\n",
    "                },\n",
    "                attrs = jointgensit_table.attrs\n",
    "            )\n",
    "            jointgensit_table_mean = jointgensit_table_reshaped.mean(['iter'],dtype='float64')\n",
    "            jointgensit_table_mean.to_netcdf(path=jointgensit_table_mean_path)\n",
    "\n",
    "    elif os.path.exists(jointgensit_table_mean_path):\n",
    "        print('Loaded',jointgensit_table_mean_path)\n",
    "        jointgensit_table_mean = xr.open_dataarray(jointgensit_table_mean_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "e68141ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "if 'jointgensit_table_mean' in globals():\n",
    "    jointgensit_table_srmses = jointgensit_table_mean.groupby('seed').map(\n",
    "        srmse,\n",
    "        ground_truth = inputs.data.ground_truth_table,\n",
    "        mask = inputs.data.test_cells_mask\n",
    "    ).values\n",
    "\n",
    "    joint_gensit_table_relative_colsum_l1_error = mean_absolute_residual_percentage_error(\n",
    "        prediction=jointgensit_table_mean,\n",
    "        ground_truth=ground_truth_table,\n",
    "        mask=inputs.data.test_cells_mask,\n",
    "        dim='origin'\n",
    "    )\n",
    "    joint_gensit_table_relative_rowsum_l1_error = mean_absolute_residual_percentage_error(\n",
    "        prediction=jointgensit_table_mean,\n",
    "        ground_truth=ground_truth_table,\n",
    "        mask=inputs.data.test_cells_mask,\n",
    "        dim='destination'\n",
    "    )\n",
    "\n",
    "if 'jointgensit_intensity_mean' in globals():\n",
    "    jointgensit_intensity_srmses = jointgensit_intensity_mean.groupby('seed').map(\n",
    "        srmse,\n",
    "        ground_truth = inputs.data.ground_truth_table,\n",
    "        mask = inputs.data.test_cells_mask\n",
    "    ).values\n",
    "\n",
    "    joint_gensit_intensity_relative_colsum_l1_error = mean_absolute_residual_percentage_error(\n",
    "        prediction=jointgensit_intensity_mean,\n",
    "        ground_truth=ground_truth_table,\n",
    "        mask=inputs.data.test_cells_mask,\n",
    "        dim='origin'\n",
    "    )\n",
    "    joint_gensit_intensity_relative_rowsum_l1_error = mean_absolute_residual_percentage_error(\n",
    "        prediction=jointgensit_intensity_mean,\n",
    "        ground_truth=ground_truth_table,\n",
    "        mask=inputs.data.test_cells_mask,\n",
    "        dim='destination'\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "342ce711",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.08488749042145591, 17.81973, 222.97024640745695)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "min(joint_gensit_table_relative_colsum_l1_error.values),max(joint_gensit_table_relative_colsum_l1_error.values),sum(joint_gensit_table_relative_colsum_l1_error.values)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f4c53656",
   "metadata": {},
   "source": [
    "# SIM_NN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "02d395e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "reload = False\n",
    "\n",
    "n_iter = 100000\n",
    "n_ensemble = 10\n",
    "seeds = range(1,11)\n",
    "sigma = 0.1414213562\n",
    "#0.1414213562, None, 0.0141421356\n",
    "\n",
    "experiment_id = 'SIM_NN_SweepedNoise__totally_and_cell_constrained_20_05_2024_15_59_08'\n",
    "sim_nn_out_path = f'../../data/outputs/DC/exp1/{experiment_id}/stored_results/'\n",
    "makedir(sim_nn_out_path)\n",
    "sigma_str = str(np.round(sigma,5) if sigma is not None else None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "b445251c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded ../../data/outputs/DC/exp1/SIM_NN_SweepedNoise__totally_and_cell_constrained_20_05_2024_15_59_08/stored_results/sim_nn_intensity_mean_E10_N100000_sigma0.14142.nc\n"
     ]
    }
   ],
   "source": [
    "sim_nn_intensity_mean_path = os.path.join(sim_nn_out_path,f'sim_nn_intensity_mean_E{n_ensemble}_N{n_iter}_sigma{sigma_str}.nc')\n",
    "if (not os.path.exists(sim_nn_intensity_mean_path) or reload):\n",
    "    settings = {\n",
    "        \"logging_mode\": \"INFO\",\n",
    "        \"coordinate_slice\": [\n",
    "            f\"da.sigma=={sigma_str}\"\n",
    "        ],\n",
    "        \"slice\":True,\n",
    "        \"metadata_keys\":[],\n",
    "        \"burnin_thinning_trimming\": [],#{'iter': {\"burnin\":10000, \"thinning\":1, \"trimming\":100000}}\n",
    "        \"sample\":[\"intensity\"],\n",
    "        \"group_by\":[],\n",
    "        \"filename_ending\":\"test\",\n",
    "        \"force_reload\":False,\n",
    "        \"n_workers\": 1\n",
    "    }\n",
    "    # Initialise outputs\n",
    "    sim_nn_outputs = Outputs(\n",
    "        config = f'../../data/outputs/DC/exp1/{experiment_id}/config.json',\n",
    "        settings = settings,\n",
    "        inputs = None,\n",
    "        slice = True,\n",
    "        level = 'NOTE'\n",
    "    )\n",
    "    # Silence outputs\n",
    "    sim_nn_outputs.logger.setLevels(console_level='NOTE')\n",
    "    # Load all data\n",
    "    sim_nn_outputs.load()\n",
    "\n",
    "    # Get data from first sweep of the experiment\n",
    "    sim_nn_outputs = sim_nn_outputs.get(0)\n",
    "\n",
    "    # Compute \n",
    "    sim_nn_intensity_means = []\n",
    "    for s in tqdm(sim_nn_outputs.data.alpha.coords['seed'].values):\n",
    "        sim_nn_outputs_group = sim_nn_outputs.select('seed',s)\n",
    "        sim_nn_intensity_group = sim_nn_outputs_group.get_sample('intensity')\n",
    "        sim_nn_intensity_means.append(sim_nn_intensity_group.mean(['iter'],dtype='float64'))\n",
    "    sim_nn_intensity_mean = xr.concat(\n",
    "        sim_nn_intensity_means, \n",
    "        dim='seed'\n",
    "    ).reset_index('sweep')\n",
    "    sim_nn_intensity_mean.to_netcdf(path=sim_nn_intensity_mean_path)\n",
    "    sim_nn_intensity_mean = sim_nn_intensity_mean.squeeze('sweep')\n",
    "elif os.path.exists(sim_nn_intensity_mean_path):\n",
    "    print('Loaded',sim_nn_intensity_mean_path)\n",
    "    sim_nn_intensity_mean = xr.open_dataarray(sim_nn_intensity_mean_path)\n",
    "    sim_nn_intensity_mean = sim_nn_intensity_mean.squeeze('sweep')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "37c155ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "if 'sim_nn_intensity_mean' in globals():\n",
    "    sim_nn_intensity_srmses = sim_nn_intensity_mean.groupby('seed').map(\n",
    "        srmse,\n",
    "        ground_truth = inputs.data.ground_truth_table,\n",
    "        mask = inputs.data.test_cells_mask\n",
    "    ).values\n",
    "\n",
    "    sim_nn_relative_colsum_l1_error = mean_absolute_residual_percentage_error(\n",
    "        prediction=sim_nn_intensity_mean,\n",
    "        ground_truth=ground_truth_table,\n",
    "        mask=inputs.data.test_cells_mask,\n",
    "        dim='origin'\n",
    "    )\n",
    "    sim_nn_relative_rowsum_l1_error = mean_absolute_residual_percentage_error(\n",
    "        prediction=sim_nn_intensity_mean,\n",
    "        ground_truth=ground_truth_table,\n",
    "        mask=inputs.data.test_cells_mask,\n",
    "        dim='destination'\n",
    "    )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "2ebaefe0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.09112755161029713, 4.043740290264162, 60.407297247292256)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "min(sim_nn_relative_colsum_l1_error.values),max(sim_nn_relative_colsum_l1_error.values),sum(sim_nn_relative_colsum_l1_error.values)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e803f1ef",
   "metadata": {},
   "source": [
    "# GMEL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "48f5cead",
   "metadata": {},
   "outputs": [],
   "source": [
    "reload = False\n",
    "n_iter = 10000\n",
    "n_ensemble = 10 \n",
    "\n",
    "experiment_id = 'GraphAttentionNetwork_Comparison_UnsetNoise__doubly_and_cell_constrained_all_region_features_16_05_2024_21_06_14'\n",
    "gmel_out_path = f'../../data/outputs/DC/comparisons/{experiment_id}/stored_results/'\n",
    "makedir(gmel_out_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "043454cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "gmel_intensity_mean_path = f'../../data/outputs/DC/comparisons/{experiment_id}/stored_results/gmel_intensity_mean_E{n_ensemble}_N{n_iter}.nc'\n",
    "if (not os.path.exists(gmel_intensity_mean_path) or reload):\n",
    "    gmel_settings = {\n",
    "        \"logging_mode\": \"INFO\",\n",
    "        \"coordinate_slice\": [\n",
    "            # \"da.seed==1\"\n",
    "        ],\n",
    "        \"slice\":False,\n",
    "        \"metadata_keys\":[],\n",
    "        \"burnin_thinning_trimming\": [],\n",
    "        \"sample\":[\"intensity\"],\n",
    "        \"group_by\":[],\n",
    "        \"filename_ending\":\"test\",\n",
    "        \"force_reload\":False,\n",
    "        \"n_workers\": 1\n",
    "    }\n",
    "\n",
    "    # Initialise outputs\n",
    "    gmel_outputs = Outputs(\n",
    "        config = f'../../data/outputs/DC/comparisons/{experiment_id}/config.json',\n",
    "        settings = gmel_settings,\n",
    "        inputs = None,\n",
    "        slice = True,\n",
    "        level = 'NOTE'\n",
    "    )\n",
    "    # Silence outputs\n",
    "    gmel_outputs.logger.setLevels(console_level='NOTE')\n",
    "    # Load all data\n",
    "    gmel_outputs.load()\n",
    "\n",
    "    # Get data from first sweep of the experiment\n",
    "    gmel_outputs = gmel_outputs.get(0)\n",
    "\n",
    "    makedir(os.path.dirname(gmel_intensity_mean_path))\n",
    "    gmel_intensity_mean = gmel_outputs.data.intensity.mean(['iter'],dtype='float64')\n",
    "    gmel_intensity_mean.to_netcdf(path=gmel_intensity_mean_path)\n",
    "else:\n",
    "    gmel_intensity_mean = xr.open_dataarray(gmel_intensity_mean_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "7abc88d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "if 'gmel_intensity_mean' in globals():\n",
    "    gmel_srmses = gmel_intensity_mean.groupby('seed').apply(\n",
    "        srmse,\n",
    "        ground_truth = inputs.data.ground_truth_table,\n",
    "        mask = inputs.data.test_cells_mask\n",
    "    ).values\n",
    "\n",
    "    gmel_relative_colsum_l1_error = mean_absolute_residual_percentage_error(\n",
    "        prediction=gmel_intensity_mean,\n",
    "        ground_truth=ground_truth_table,\n",
    "        mask=inputs.data.test_cells_mask,\n",
    "        dim='origin'\n",
    "    )\n",
    "    gmel_relative_rowsum_l1_error = mean_absolute_residual_percentage_error(\n",
    "        prediction=gmel_intensity_mean,\n",
    "        ground_truth=ground_truth_table,\n",
    "        mask=inputs.data.test_cells_mask,\n",
    "        dim='destination'\n",
    "    )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "6f07e28b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.1993185163816306, 1.1839352152828058, 23.03026892970707)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "min(gmel_relative_colsum_l1_error.values),max(gmel_relative_colsum_l1_error.values),sum(gmel_relative_colsum_l1_error.values)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ecbda455",
   "metadata": {},
   "source": [
    "# Plots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "cfeac10e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Joint GeNSIT min error: 0.08488749042145591 max error: 17.81973 total error: 222.97024640745695\n",
      "SIM NN min error: 0.09112755161029713 max error: 4.043740290264162 total error: 60.407297247292256\n",
      "GMEL min error: 0.1993185163816306 max error: 1.1839352152828058 total abs error: 23.030268929707074\n",
      "Compiling figure for GMEL over destinations\n",
      "Compiling figure for SIM NN over destinations\n",
      "Compiling figure for GeNSIT (Joint) over destinations\n",
      "origin sum vmin 0.08 vmax 28\n",
      "Joint GeNSIT min error: 0.006829333333333375 max error: 8.50722 total error: 91.91671275929096\n",
      "SIM NN min error: 0.14371955803725983 max error: 4.324900778870562 total error: 127.74352259234195\n",
      "GMEL min error: 0.3744096871917689 max error: 28.19479265778898 total abs error: 182.1748494670865\n",
      "Compiling figure for GMEL over origins\n",
      "Compiling figure for SIM NN over origins\n",
      "Compiling figure for GeNSIT (Joint) over origins\n",
      "destination sum vmin 0.08 vmax 28\n"
     ]
    }
   ],
   "source": [
    "for sum_dim in ['origin','destination']:\n",
    "    region_geometries = getattr(inputs.data,'region_geometries')\n",
    "\n",
    "    if sum_dim == 'destination':\n",
    "        plot_dim = 'origin'\n",
    "        gmel_quantity = gmel_relative_rowsum_l1_error\n",
    "        sim_nn_quantity = sim_nn_relative_rowsum_l1_error\n",
    "        joint_gensit_quantity = joint_gensit_table_relative_rowsum_l1_error\n",
    "\n",
    "    elif sum_dim == 'origin':\n",
    "        plot_dim = 'destination'\n",
    "        gmel_quantity = gmel_relative_colsum_l1_error\n",
    "        sim_nn_quantity = sim_nn_relative_colsum_l1_error\n",
    "        joint_gensit_quantity = joint_gensit_table_relative_colsum_l1_error\n",
    "\n",
    "    min_error = min(np.min(gmel_quantity.values),np.min(sim_nn_quantity.values),np.min(joint_gensit_quantity.values))\n",
    "    max_error = max(np.max(gmel_quantity.values),np.max(sim_nn_quantity.values),np.max(joint_gensit_quantity.values))\n",
    "\n",
    "    if 'joint_gensit_quantity' in globals():\n",
    "        print(f\"Joint GeNSIT min error: {np.min(joint_gensit_quantity.values)} max error: {np.max(joint_gensit_quantity.values)} total error: {np.sum(joint_gensit_quantity.values)}\")\n",
    "    if 'sim_nn_quantity' in globals():\n",
    "        print(f\"SIM NN min error: {np.min(sim_nn_quantity.values)} max error: {np.max(sim_nn_quantity.values)} total error: {np.sum(sim_nn_quantity.values)}\")\n",
    "    if 'gmel_quantity' in globals():\n",
    "        print(f\"GMEL min error: {np.min(gmel_quantity.values)} max error: {np.max(gmel_quantity.values)} total abs error: {np.sum(gmel_quantity.values)}\")\n",
    "\n",
    "    gmel_quantity_with_geometries = pd.merge(\n",
    "        gmel_quantity.to_pandas().reset_index().rename(columns={0:\"error\"}),\n",
    "        region_geometries[['LOCATIONID','geometry']],\n",
    "        how = 'left',\n",
    "        left_on = plot_dim,\n",
    "        right_on = 'LOCATIONID'\n",
    "    ) \n",
    "    # Convert back to geodataframe\n",
    "    gmel_quantity_with_geometries = gpd.GeoDataFrame(gmel_quantity_with_geometries.drop(columns=['LOCATIONID']))\n",
    "\n",
    "    joint_gensit_quantity_with_geometries = pd.merge(\n",
    "        joint_gensit_quantity.to_pandas().reset_index().rename(columns={0:\"error\"}),\n",
    "        region_geometries[['LOCATIONID','geometry']],\n",
    "        how = 'left',\n",
    "        left_on = plot_dim,\n",
    "        right_on = 'LOCATIONID'\n",
    "    ) \n",
    "    # Convert back to geodataframe\n",
    "    joint_gensit_quantity_with_geometries = gpd.GeoDataFrame(joint_gensit_quantity_with_geometries.drop(columns=['LOCATIONID']))\n",
    "\n",
    "\n",
    "    sim_nn_quantity_with_geometries = pd.merge(\n",
    "        sim_nn_quantity.to_pandas().reset_index().rename(columns={0:\"error\"}),\n",
    "        region_geometries[['LOCATIONID','geometry']],\n",
    "        how = 'left',\n",
    "        left_on = plot_dim,\n",
    "        right_on = 'LOCATIONID'\n",
    "    ) \n",
    "    # Convert back to geodataframe\n",
    "    sim_nn_quantity_with_geometries = gpd.GeoDataFrame(sim_nn_quantity_with_geometries.drop(columns=['LOCATIONID']))\n",
    "\n",
    "    # Plot settings\n",
    "    plot_settings = {\n",
    "        \"figure_size\":(10,10),\n",
    "        \"colourmap\":\"Reds\",\n",
    "        \"figure_format\":\"ps\",\n",
    "        \"figure_title\":\"figure5/mean_residual\",\n",
    "        \"legend_axis\":[0,0],\n",
    "        \"axis_title_size\":30,\n",
    "        \n",
    "        \"x_label\":\"Longitude\",\n",
    "        \"x_label_size\":18,\n",
    "        \"x_label_pad\":7,\n",
    "        \"x_tick_size\":16,\n",
    "        \"x_tick_rotation\":None,\n",
    "        \"x_tick_pad\":5,\n",
    "        \"x_label_rotation\":0,\n",
    "        \n",
    "        \"y_label\":\"Latitude\",\n",
    "        \"y_label_size\":18,\n",
    "        \"y_label_pad\":7,\n",
    "        \"y_tick_size\":16,\n",
    "        \"y_tick_rotation\":None,\n",
    "        \"y_tick_pad\":5,\n",
    "        \"y_label_rotation\":90,\n",
    "        \n",
    "        \"vmin\":0.08,#min_error,\n",
    "        \"vmax\":28,#max_error,\n",
    "        \"colourbar\":False\n",
    "    }\n",
    "\n",
    "    for model,data in [\n",
    "        (\"GMEL\",gmel_quantity_with_geometries),\n",
    "        (\"SIM NN\",sim_nn_quantity_with_geometries),\n",
    "        (\"GeNSIT (Joint)\",joint_gensit_quantity_with_geometries),\n",
    "        \n",
    "    ]:\n",
    "        \n",
    "        print(f\"Compiling figure for {model} over {plot_dim}s\")\n",
    "        # Figure size \n",
    "        fig, ax = plt.subplots(\n",
    "            figsize = plot_settings.get('figure_size',None),\n",
    "            ncols = 1,\n",
    "            nrows = 1,\n",
    "            squeeze = False\n",
    "        )\n",
    "\n",
    "        # Set colormap\n",
    "        cmap = plt.get_cmap(plot_settings.get('colourmap',None))\n",
    "        norm = mpl.colors.LogNorm(vmin=plot_settings[\"vmin\"], vmax=plot_settings[\"vmax\"])\n",
    "\n",
    "        # Global axes label\n",
    "        for var in ['x','y']:\n",
    "            if plot_settings.get(f'{var}_label',''):\n",
    "                axis_label = plot_settings[f'{var}_label'].replace(\"_\",\" \")\n",
    "                getattr(plt,f\"{var}label\",plt.xlabel)(\n",
    "                    axis_label,\n",
    "                    fontsize = plot_settings.get(f'{var}_label_size',None),\n",
    "                    labelpad = plot_settings.get(f'{var}_label_pad',None),\n",
    "                    rotation = plot_settings.get(f'{var}_label_rotation',None)\n",
    "                )\n",
    "                ax[0,0].tick_params(\n",
    "                    axis = var, \n",
    "                    pad = plot_settings.get(f\"{var}_tick_pad\",None),\n",
    "                    bottom = True,\n",
    "                    labelsize = plot_settings.get(f\"{var}_tick_size\",None),\n",
    "                    rotation = plot_settings.get(f\"{var}_tick_rotation\",None)\n",
    "                )\n",
    "        ax[0,0] = data.plot(\n",
    "                column = 'error',\n",
    "                ax = ax[0,0],\n",
    "                alpha = 1,\n",
    "                markersize = 2.0,\n",
    "                linewidth=2, \n",
    "                edgecolor='black',\n",
    "                cmap = cmap,\n",
    "                # norm = mpl.colors.Normalize(vmin=plot_settings[\"vmin\"], vmax=plot_settings[\"vmax\"]),\n",
    "                norm = norm,\n",
    "                legend = plot_settings['colourbar']\n",
    "            )\n",
    "        ax[0,0].set_title(\n",
    "            model,\n",
    "            fontdict = {'fontsize':plot_settings.get('axis_title_size',None)}\n",
    "        )\n",
    "        if sum_dim == 'origin':\n",
    "            text_loc = (0.75, 0.87)\n",
    "        else:\n",
    "            text_loc = (0.73, 0.87)\n",
    "        fig.text(\n",
    "            text_loc[0], text_loc[1], f\"Mean abs. \\% error: {np.round(data.error.mean(),1)}\", \n",
    "            ha='right', va='top', fontsize=16, \n",
    "            bbox=dict(facecolor='none', edgecolor='none', alpha=0)\n",
    "        )\n",
    "        ax[0,0].tick_params(labelsize=plot_settings['x_tick_size'])\n",
    "        if len(ax[0,0].get_figure().get_axes()) > 1:\n",
    "            # Access the colorbar\n",
    "            cbar = ax[0,0].get_figure().get_axes()[1]\n",
    "            # Set the fontsize of the colorbar\n",
    "            cbar.tick_params(labelsize=plot_settings['x_tick_size'])\n",
    "\n",
    "        write_figure(\n",
    "            fig,\n",
    "            f\"../../data/outputs/DC/exp1/paper_figures/residuals/{model}_{plot_dim}\",\n",
    "            figure_format=plot_settings.get('figure_format',''),\n",
    "            pad_inches=0.0,\n",
    "            bbox_inches='tight'\n",
    "        )\n",
    "\n",
    "    # Create a separate figure for horizontal colorbar\n",
    "    fig_cbar, ax_cbar = plt.subplots(figsize=(8, 1))  # Wide and short\n",
    "\n",
    "    print(f'{sum_dim} sum','vmin',plot_settings['vmin'],'vmax',plot_settings['vmax'])\n",
    "    # Use same colormap and normalization as main plot\n",
    "    sm = mpl.cm.ScalarMappable(cmap=cmap, norm=norm)\n",
    "    sm.set_array([])  # Required for colorbar creation in older versions\n",
    "\n",
    "    # Create horizontal colorbar\n",
    "    cbar = fig_cbar.colorbar(sm, cax=ax_cbar, orientation='horizontal')\n",
    "    cbar.ax.tick_params(labelsize=plot_settings['x_tick_size'])\n",
    "\n",
    "    # Optional: customize labels or add title\n",
    "    # cbar.set_label(\"Error Value\", fontsize=14)\n",
    "\n",
    "    # Clean layout\n",
    "    fig_cbar.tight_layout()\n",
    "\n",
    "    write_figure(\n",
    "        fig_cbar,\n",
    "        f\"../../data/outputs/DC/exp1/paper_figures/residuals/{plot_dim}_colorbar\",\n",
    "        figure_format=plot_settings.get('figure_format',''),\n",
    "        pad_inches=0.0,\n",
    "        bbox_inches='tight'\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ebe31c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sanity check\n",
    "(inputs.data.train_cells.shape[0] + \\\n",
    "inputs.data.test_cells.shape[0] + \\\n",
    "inputs.data.validation_cells.shape[0]) \\\n",
    "== \\\n",
    "ground_truth_table.shape[0]*ground_truth_table.shape[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba82f2a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot train / test / validation split\n",
    "table_masks = deepcopy(ground_truth_table)\n",
    "table_masks[:] = 0\n",
    "table_masks += inputs.data.train_cells_mask.astype(int)\n",
    "table_masks += 2*inputs.data.test_cells_mask.astype(int)\n",
    "table_masks += 3*inputs.data.validation_cells_mask.astype(int)\n",
    "\n",
    "new_destinations = np.where(np.all(table_masks == 2, axis=0))[0]\n",
    "new_origins = np.where(np.all(table_masks == 2, axis=1))[0]\n",
    "print('new destinations',new_destinations)\n",
    "print('new origins',new_origins)\n",
    "print(\"Total test destinations\",len(np.unique(inputs.data.test_cells[:,0])))\n",
    "print(\"Total test origins\",len(np.unique(inputs.data.test_cells[:,1])))\n",
    "\n",
    "test_cells_df = pd.DataFrame(inputs.data.test_cells.astype(int), columns=[\"origin\", \"destination\"])\n",
    "# Count unique values in column 2 (value) per unique value in column 1 (key)\n",
    "print(\"Total test origins by test destination\",test_cells_df.groupby(\"origin\")[\"destination\"].nunique())\n",
    "print(\"Total test destinations by test origin\",test_cells_df.groupby(\"destination\")[\"origin\"].nunique())\n",
    "\n",
    "fig,ax = plt.subplots(1,1,figsize=(10, 10))\n",
    "colors = ['green', 'red', 'blue']\n",
    "cmap = mpl.colors.ListedColormap(colors)\n",
    "heatmap = plt.imshow(table_masks, cmap=cmap, aspect='equal', interpolation='nearest')\n",
    "cbar = plt.colorbar(ticks=[1, 2, 3],fraction=0.046, pad=0.04)\n",
    "cbar.set_ticklabels(['Train', 'Test', 'Validation'])\n",
    "cbar.ax.tick_params(labelsize=14)\n",
    "ax.set_xticks([])\n",
    "ax.set_yticks([])\n",
    "ax.set_xlabel('Destinations', fontsize=16)\n",
    "ax.set_ylabel('Origins', fontsize=16)\n",
    "# fig.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "fig.savefig(\n",
    "    f\"../../data/outputs/DC/exp1/paper_figures/train_test_split/train_test_validation_split.pdf\",\n",
    "    format='pdf'\n",
    ")\n",
    "# write_figure(\n",
    "#     fig,\n",
    "#     f\"../../data/outputs/DC/exp1/paper_figures/train_test_split/train_test_validation_split\",\n",
    "#     figure_format=plot_settings.get('figure_format',''),\n",
    "#     pad_inches=0.0,\n",
    "#     bbox_inches='tight'\n",
    "# )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a6028504",
   "metadata": {},
   "outputs": [],
   "source": [
    "# fig,ax = plt.subplots(1,1,figsize=(10, 10))\n",
    "# plt.title('New destinations')\n",
    "# region_geometries.boundary.plot(ax=ax)\n",
    "# region_geometries[region_geometries.LOCATIONID.isin(new_destinations)].plot(ax=ax,color='red', edgecolor='black')\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "db629917",
   "metadata": {},
   "source": [
    "# Statistical significance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19a4b328",
   "metadata": {},
   "outputs": [],
   "source": [
    "print('GMEL',np.mean(gmel_srmses),np.std(gmel_srmses))\n",
    "print('SIM_NN',np.mean(sim_nn_intensity_srmses),np.std(sim_nn_intensity_srmses))\n",
    "print('Joint GeNSIT',np.mean(jointgensit_table_srmses),np.std(jointgensit_table_srmses))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb7a7a71",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "gensit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

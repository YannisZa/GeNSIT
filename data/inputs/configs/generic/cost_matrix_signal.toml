log_level = 'info'
sweep_mode = true

[inputs]
n_workers = +1
n_threads = [+6,+6]
device = 'cpu'
in_directory = './data/inputs/'
dataset = 'cambridge_work_commuter_lsoas_to_msoas'
load_experiment = ''
# [inputs.seed.sweep]
  # default = 0
  # range = ["0:99:1"]
[inputs.to_learn.sweep]
  default = ['alpha', 'beta'] 
  range = [['alpha', 'beta'],['alpha', 'beta']]#,
  # ['alpha', 'beta', 'sigma']]
  coupled = true
  target_name = 'sigma'
  
[inputs.data]
    [inputs.data.origin_demand]
      file = 'origin_demand_sum_normalised.txt'
    [inputs.data.destination_attraction_ts]
      file ='destination_attraction_time_series_sum_normalised.txt'
    [inputs.data.ground_truth_table]
      file = 'table_lsoas_to_msoas.txt'
    [inputs.data.total_cost_by_origin]
      file = 'lsoas_total_distance_to_work.txt'
    [inputs.data.cost_matrix]
      file = """cost_matrices/clustered_facilities_sample_20x20_20_01_2023_\
      sample_20x20_clustered_facilities_ripleys_k_500_euclidean_points%_\
      prob_origin_destination_adjusted_normalised_boundary_only_\
      edge_corrected_cost_matrix_max_normalised.txt"""

[contingency_table]
  sparse_margins = false
  [contingency_table.constraints.axes.sweep]
    default = [[+0,+1]]
    range = [[[+0,+1]], [[+1]]]
    coupled = true
    target_name = 'title'
  [contingency_table.constraints]
    cells = ''
  
[spatial_interaction_model]
  [spatial_interaction_model.name.sweep]
    default = 'TotallyConstrained'
    range = ['TotallyConstrained','ProductionConstrained']
    coupled = true
    target_name = 'title'
  
  [spatial_interaction_model.parameters]
    bmax = +250.0
    
[harris_wilson_model]
  dt = +0.001
  [harris_wilson_model.parameters]
    noise_percentage = +3.0 #+0.000_1
    epsilon = +1.0
    # kappa = +1.0000000596046483
    # delta = 0.0
    [harris_wilson_model.parameters.sigma.sweep]
      default = 0.0141421356
      range = [0.0141421356, 0.1414213562]
      #, nan]

[training]
  num_steps = +1
  batch_size = +1
  N = 1000

[mcmc]
    disable_tqdm = true
    mcmc_workers = +1
    
    [mcmc.contingency_table]
      table_steps = +1
      proposal = 'direct_sampling'
      table0 = 'maximum_entropy_solution'
      margin0 = 'multinomial'

    [mcmc.parameters]
      theta_steps = 1
      step_size = 1.0
      [mcmc.parameters.covariance.sweep]
        default = [[0.0149674,0.00182529],[0.00182529,0.0109968]]
        range = [
          [[0.0149674,0.00182529],[0.00182529,0.0109968]],
          [[1.0,0.0],[0.0,1.0]]
        ]
        #[[ 0.0349674,  0.00], [ 0.00,  0.0349968]]
        coupled = true
        target_name = 'sigma'
    [mcmc.destination_attraction]
      log_destination_attraction_steps = 1
      leapfrog_steps = 10
      leapfrog_step_size = 0.1 #0.02
      ais_leapfrog_steps = 3#10
      ais_leapfrog_step_size = 0.2#0.1
      ais_samples = 10
      n_bridging_distributions = 50

[neural_network]
  disable_tqdm = true
  [neural_network.loss]
    loss_name = ['dest_attraction_ts_loss']
    loss_function = ['mseloss']
    loss_kwarg_keys = [[]]
  [neural_network.hyperparameters]
    num_layers = +1
    optimizer = 'Adam'
    learning_rate = +0.002
    [neural_network.hyperparameters.biases]
      default = [+0.0, +4.0]
      [neural_network.hyperparameters.biases.layer_specific]
    [neural_network.hyperparameters.nodes_per_layer]
      default = +20
      [neural_network.hyperparameters.nodes_per_layer.layer_specific]
    [neural_network.hyperparameters.activation_funcs]
      default = 'linear'
      [neural_network.hyperparameters.activation_funcs.layer_specific]
        1 = 'abs'

[[experiments]]
  type = 'RSquared_Analysis'
  comment = 'R^2 of model minimum potential grid search'
  disable_tqdm = false
  export_samples = true
  export_metadata = true
  overwrite = true
  [experiments.grid_ranges.alpha]
    min = 0.01
    max = 2.0
    n = 100
  [experiments.grid_ranges.beta]
    min = 0.01
    max = 2.0
    n = 100

[[experiments]]
  type = 'LogTarget_Analysis'
  comment = 'Log target distribution of Markov Chain Monte Carlo grid search'
  disable_tqdm = false
  export_samples = true
  export_metadata = true
  overwrite = true
  [experiments.grid_ranges.alpha]
    min = 0.01
    max = 2.0
    n = 100
  [experiments.grid_ranges.beta]
    min = 0.01
    max = 2.0
    n = 100

[outputs]
    chunk_size = +20_000
    write_start = +1
    write_every = +1
    out_directory = './data/outputs/'
    out_group = 'cm_signal'
    [outputs.title.sweep]
      default = '_total_constrained'
      range = ['_total_constrained','_row_constrained']